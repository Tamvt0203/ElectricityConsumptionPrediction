{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', index_col='date')\n",
    "df_test = pd.read_csv('test.csv',index_col='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chia tập validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validate = df_train.iloc[-100:, :]\n",
    "df_train = df_train.iloc[:-100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(630, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>temperature</th>\n",
       "      <th>new_total_usage</th>\n",
       "      <th>weekday_0</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>True</td>\n",
       "      <td>21.89</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02</th>\n",
       "      <td>False</td>\n",
       "      <td>21.96</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>True</td>\n",
       "      <td>21.99</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>False</td>\n",
       "      <td>22.57</td>\n",
       "      <td>4037.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>False</td>\n",
       "      <td>22.97</td>\n",
       "      <td>4191.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            is_holiday  temperature  new_total_usage  weekday_0  weekday_1  \\\n",
       "date                                                                         \n",
       "2022-01-01        True        21.89           1496.0      False      False   \n",
       "2022-01-02       False        21.96           1177.0      False      False   \n",
       "2022-01-03        True        21.99           1463.0       True      False   \n",
       "2022-01-04       False        22.57           4037.0      False       True   \n",
       "2022-01-05       False        22.97           4191.0      False      False   \n",
       "\n",
       "            weekday_2  weekday_3  weekday_4  weekday_5  weekday_6  \n",
       "date                                                               \n",
       "2022-01-01      False      False      False       True      False  \n",
       "2022-01-02      False      False      False      False       True  \n",
       "2022-01-03      False      False      False      False      False  \n",
       "2022-01-04      False      False      False      False      False  \n",
       "2022-01-05       True      False      False      False      False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chuẩn bị dữ liệu để train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuyển kiểu dữ liệu True/False thành 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_columns_to_int(df, weekday_cols_prefix='weekday_', holiday_col='is_holiday', num_weekdays=6):\n",
    "    \"\"\"\n",
    "    Chuyển đổi các cột 'weekday' và 'is_holiday' của DataFrame sang kiểu dữ liệu int.\n",
    "\n",
    "    Tham số:\n",
    "    - df: DataFrame cần chuyển đổi.\n",
    "    - weekday_cols_prefix: Tiền tố của các cột 'weekday'. Mặc định là 'weekday_'.\n",
    "    - holiday_col: Tên cột ngày lễ cần chuyển đổi. Mặc định là 'is_holiday'.\n",
    "    - num_weekdays: Số lượng cột 'weekday' cần chuyển đổi (mặc định là 6).\n",
    "    \n",
    "    Trả về:\n",
    "    - DataFrame với các cột đã được chuyển sang kiểu int.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Chuyển đổi các cột weekday_{i} thành int\n",
    "    for i in range(0, num_weekdays + 1):  # Lặp từ 1 tới num_weekdays\n",
    "        df[f'{weekday_cols_prefix}{i}'] = df[f'{weekday_cols_prefix}{i}'].astype(int)\n",
    "    \n",
    "    # Chuyển đổi cột is_holiday thành int\n",
    "    df[holiday_col] = df[holiday_col].astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = convert_columns_to_int(df=df_train)\n",
    "df_validate = convert_columns_to_int(df=df_validate)\n",
    "df_test = convert_columns_to_int(df=df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale dữ liệu số về 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['temperature', 'new_total_usage']\n",
    "scaler = MinMaxScaler()\n",
    "df_train[numerical_cols] = scaler.fit_transform(df_train[numerical_cols])\n",
    "df_test[numerical_cols] = scaler.transform(df_test[numerical_cols])\n",
    "df_validate[numerical_cols] = scaler.transform(df_validate[numerical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>temperature</th>\n",
       "      <th>new_total_usage</th>\n",
       "      <th>weekday_0</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>0.346911</td>\n",
       "      <td>0.100282</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>0</td>\n",
       "      <td>0.332654</td>\n",
       "      <td>0.313559</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>0</td>\n",
       "      <td>0.300747</td>\n",
       "      <td>0.498588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-04</th>\n",
       "      <td>0</td>\n",
       "      <td>0.272234</td>\n",
       "      <td>0.497175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-05</th>\n",
       "      <td>0</td>\n",
       "      <td>0.316361</td>\n",
       "      <td>0.498588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            is_holiday  temperature  new_total_usage  weekday_0  weekday_1  \\\n",
       "date                                                                         \n",
       "2024-01-01           1     0.346911         0.100282          1          0   \n",
       "2024-01-02           0     0.332654         0.313559          0          1   \n",
       "2024-01-03           0     0.300747         0.498588          0          0   \n",
       "2024-01-04           0     0.272234         0.497175          0          0   \n",
       "2024-01-05           0     0.316361         0.498588          0          0   \n",
       "\n",
       "            weekday_2  weekday_3  weekday_4  weekday_5  weekday_6  \n",
       "date                                                               \n",
       "2024-01-01          0          0          0          0          0  \n",
       "2024-01-02          0          0          0          0          0  \n",
       "2024-01-03          1          0          0          0          0  \n",
       "2024-01-04          0          1          0          0          0  \n",
       "2024-01-05          0          0          1          0          0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_past = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tạo tập X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giải thích: mỗi dòng dữ liệu ở tập X sẽ bao gồm n_past dòng dữ liệu ở quá khứ (bao gồm cả 8 features và 1 target value), tập y sẽ là target value ở dòng dữ liệu n_past+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createXY(dataset,n_past):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(n_past, len(dataset)):\n",
    "            dataX.append(dataset.iloc[i - n_past:i, 0:dataset.shape[1]])\n",
    "            dataY.append(dataset.iloc[i,2])\n",
    "    return np.array(dataX),np.array(dataY)\n",
    "trainX,trainY=createXY(df_train,n_past=n_past)\n",
    "testX,testY=createXY(df_test,n_past=n_past)\n",
    "validX, validY = createXY(df_validate, n_past=n_past)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 30, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = trainX.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 30, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.25458248, 0.16384181, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 1.        , 0.        ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_holiday         1.000000\n",
       "temperature        0.254582\n",
       "new_total_usage    0.163842\n",
       "weekday_0          0.000000\n",
       "weekday_1          0.000000\n",
       "weekday_2          0.000000\n",
       "weekday_3          0.000000\n",
       "weekday_4          0.000000\n",
       "weekday_5          1.000000\n",
       "weekday_6          0.000000\n",
       "Name: 2022-01-01, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.2742702 , 0.12711864, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 1.        ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0][29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_holiday         0.000000\n",
       "temperature        0.274270\n",
       "new_total_usage    0.127119\n",
       "weekday_0          0.000000\n",
       "weekday_1          0.000000\n",
       "weekday_2          0.000000\n",
       "weekday_3          0.000000\n",
       "weekday_4          0.000000\n",
       "weekday_5          0.000000\n",
       "weekday_6          1.000000\n",
       "Name: 2022-01-30, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[29, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12853107344630849"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_holiday         1.000000\n",
       "temperature        0.213170\n",
       "new_total_usage    0.128531\n",
       "weekday_0          1.000000\n",
       "weekday_1          0.000000\n",
       "weekday_2          0.000000\n",
       "weekday_3          0.000000\n",
       "weekday_4          0.000000\n",
       "weekday_5          0.000000\n",
       "weekday_6          0.000000\n",
       "Name: 2022-01-31, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[30, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the build_model function\n",
    "# def build_model(optimizer='adam'):\n",
    "#     grid_model = Sequential()\n",
    "#     grid_model.add(LSTM(90, return_sequences=True, input_shape=(n_past, n_cols)))\n",
    "#     grid_model.add(LSTM(90))\n",
    "#     grid_model.add(Dropout(0.2))\n",
    "#     grid_model.add(Dense(1))\n",
    "#     grid_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "#     return grid_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 1D CNN Layers\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_past, n_cols)))\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "    model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    # Stacked Bidirectional LSTM Layers\n",
    "    model.add(Bidirectional(LSTM(100, return_sequences=True)))  # First Bi-LSTM layer\n",
    "    model.add(Bidirectional(LSTM(100)))  # Second Bi-LSTM layer\n",
    "\n",
    "    # Dense Output Layer\n",
    "    model.add(Dense(1, activation='linear'))  # For regression tasks (predicted value)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mape(y, y_pred):\n",
    "    y = np.array(y)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Tránh chia cho 0\n",
    "    non_zero_indices = y != 0\n",
    "    y_non_zero = y[non_zero_indices]\n",
    "    y_pred_non_zero = y_pred[non_zero_indices]\n",
    "    \n",
    "    # Tính MAPE\n",
    "    mape = np.mean(np.abs((y_non_zero - y_pred_non_zero) / y_non_zero)) * 100\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stock_prediction(y_pred, validY, scaler, numerical_cols, title='Predict Electricity Consumption'):\n",
    "    \"\"\"\n",
    "    Hàm dự đoán và vẽ biểu đồ cho dữ liệu giá cổ phiếu dựa trên mô hình và scaler.\n",
    "\n",
    "    Tham số:\n",
    "    - y_pred: Dự đoán của mô hình, đầu vào cần được reshape\n",
    "    - validY: Giá trị thực của dữ liệu kiểm tra, đầu vào cần được reshape\n",
    "    - scaler: Bộ scaler đã được dùng để chuẩn hóa dữ liệu\n",
    "    - numerical_cols: Số lượng cột dữ liệu (các thuộc tính số cần dự đoán)\n",
    "    - title: Tiêu đề của biểu đồ (tùy chọn)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reshape y_pred và validY để chuẩn bị cho việc đảo ngược chuẩn hóa\n",
    "    y_pred = y_pred.reshape(-1, 1)\n",
    "    validY = validY.reshape(-1, 1)\n",
    "    \n",
    "    # Tạo các bản sao của y_pred và validY với số cột bằng số lượng thuộc tính số\n",
    "    y_pred_copies_array = np.repeat(y_pred, len(numerical_cols), axis=-1)\n",
    "    y_copies_array = np.repeat(validY, len(numerical_cols), axis=-1)\n",
    "    \n",
    "    # Inverse transform để đưa dữ liệu về giá trị ban đầu\n",
    "    y_pred_before_scale = scaler.inverse_transform(y_pred_copies_array)[:, -1]\n",
    "    y_before_scale = scaler.inverse_transform(y_copies_array)[:, -1]\n",
    "    print(calculate_mape(y_pred=y_pred_before_scale, y=y_before_scale))\n",
    "    \n",
    "    \n",
    "    # Vẽ biểu đồ\n",
    "    plt.plot(y_before_scale, color='red', label='Real Electricity Consumption')\n",
    "    plt.plot(y_pred_before_scale, color='blue', label='Predicted Electricity Consumption')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Electricity Consumption')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\.conda\\envs\\time_series_env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = build_model(optimizer='Adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'saved_models'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Define the checkpoint callback to save only 5 most recent models\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=os.path.join(save_dir, 'model_epoch_{epoch:02d}_loss_{loss:.4f}.keras'), \n",
    "    monitor='loss',\n",
    "    save_best_only=False,  # Save the model every epoch\n",
    "    mode='auto',\n",
    "    verbose=1,\n",
    "    save_weights_only=False  # Save the entire model (architecture + weights)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_checkpoint(directory):\n",
    "    model_files = sorted(\n",
    "        [f for f in os.listdir(directory) if f.endswith('.keras')],\n",
    "        key=lambda x: os.path.getmtime(os.path.join(directory, x))\n",
    "    )\n",
    "    \n",
    "    if model_files:\n",
    "        latest_model = model_files[-1]\n",
    "        print(f\"Loading model: {latest_model}\")\n",
    "        return load_model(os.path.join(directory, latest_model))\n",
    "    else:\n",
    "        print(\"No model found, training from scratch.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_least_loss_model(directory):\n",
    "    # Regular expression to extract loss from the filename\n",
    "    loss_pattern = re.compile(r'_loss_([0-9]+\\.[0-9]+)\\.keras')\n",
    "\n",
    "    # Find all model files and extract loss values\n",
    "    model_files_with_loss = []\n",
    "    for f in os.listdir(directory):\n",
    "        if f.endswith('.keras'):\n",
    "            match = loss_pattern.search(f)\n",
    "            if match:\n",
    "                loss_value = float(match.group(1))\n",
    "                model_files_with_loss.append((f, loss_value))\n",
    "\n",
    "    # If there are models available, sort by loss and return the one with the least loss\n",
    "    if model_files_with_loss:\n",
    "        model_files_with_loss.sort(key=lambda x: x[1])  # Sort by loss value (second item in tuple)\n",
    "        least_loss_model = model_files_with_loss[0][0]  # Get the filename with the least loss\n",
    "        print(f\"Loading model with the least loss: {least_loss_model}\")\n",
    "        return load_model(os.path.join(directory, least_loss_model))\n",
    "    else:\n",
    "        print(\"No model found, training from scratch.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model with the least loss: model_epoch_932_loss_0.0502.keras\n",
      "Epoch 1/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0515\n",
      "Epoch 1: saving model to saved_models\\model_epoch_01_loss_0.0528.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - loss: 0.0517 - val_loss: 0.0492\n",
      "Epoch 2/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0546\n",
      "Epoch 2: saving model to saved_models\\model_epoch_02_loss_0.0527.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0545 - val_loss: 0.0492\n",
      "Epoch 3/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0504\n",
      "Epoch 3: saving model to saved_models\\model_epoch_03_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0505 - val_loss: 0.0492\n",
      "Epoch 4/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0546\n",
      "Epoch 4: saving model to saved_models\\model_epoch_04_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0542 - val_loss: 0.0492\n",
      "Epoch 5/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0516\n",
      "Epoch 5: saving model to saved_models\\model_epoch_05_loss_0.0528.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0518 - val_loss: 0.0492\n",
      "Epoch 6/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0508\n",
      "Epoch 6: saving model to saved_models\\model_epoch_06_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0509 - val_loss: 0.0493\n",
      "Epoch 7/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0516\n",
      "Epoch 7: saving model to saved_models\\model_epoch_07_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0516 - val_loss: 0.0493\n",
      "Epoch 8/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0509\n",
      "Epoch 8: saving model to saved_models\\model_epoch_08_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0510 - val_loss: 0.0493\n",
      "Epoch 9/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0502\n",
      "Epoch 9: saving model to saved_models\\model_epoch_09_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0503 - val_loss: 0.0492\n",
      "Epoch 10/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0529\n",
      "Epoch 10: saving model to saved_models\\model_epoch_10_loss_0.0525.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0528 - val_loss: 0.0492\n",
      "Epoch 11/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0530\n",
      "Epoch 11: saving model to saved_models\\model_epoch_11_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0529 - val_loss: 0.0492\n",
      "Epoch 12/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0525\n",
      "Epoch 12: saving model to saved_models\\model_epoch_12_loss_0.0526.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0525 - val_loss: 0.0492\n",
      "Epoch 13/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0512\n",
      "Epoch 13: saving model to saved_models\\model_epoch_13_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0513 - val_loss: 0.0492\n",
      "Epoch 14/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0531\n",
      "Epoch 14: saving model to saved_models\\model_epoch_14_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0530 - val_loss: 0.0493\n",
      "Epoch 15/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0491\n",
      "Epoch 15: saving model to saved_models\\model_epoch_15_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0495 - val_loss: 0.0493\n",
      "Epoch 16/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0526\n",
      "Epoch 16: saving model to saved_models\\model_epoch_16_loss_0.0524.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0526 - val_loss: 0.0493\n",
      "Epoch 17/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0522\n",
      "Epoch 17: saving model to saved_models\\model_epoch_17_loss_0.0528.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0523 - val_loss: 0.0492\n",
      "Epoch 18/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0510\n",
      "Epoch 18: saving model to saved_models\\model_epoch_18_loss_0.0528.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0513 - val_loss: 0.0492\n",
      "Epoch 19/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0482\n",
      "Epoch 19: saving model to saved_models\\model_epoch_19_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0488 - val_loss: 0.0492\n",
      "Epoch 20/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0520\n",
      "Epoch 20: saving model to saved_models\\model_epoch_20_loss_0.0525.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0521 - val_loss: 0.0492\n",
      "Epoch 21/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0495\n",
      "Epoch 21: saving model to saved_models\\model_epoch_21_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0498 - val_loss: 0.0492\n",
      "Epoch 22/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0511\n",
      "Epoch 22: saving model to saved_models\\model_epoch_22_loss_0.0526.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0512 - val_loss: 0.0491\n",
      "Epoch 23/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0549\n",
      "Epoch 23: saving model to saved_models\\model_epoch_23_loss_0.0541.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0548 - val_loss: 0.0491\n",
      "Epoch 24/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0514\n",
      "Epoch 24: saving model to saved_models\\model_epoch_24_loss_0.0536.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0517 - val_loss: 0.0491\n",
      "Epoch 25/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0545\n",
      "Epoch 25: saving model to saved_models\\model_epoch_25_loss_0.0541.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0545 - val_loss: 0.0491\n",
      "Epoch 26/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0537\n",
      "Epoch 26: saving model to saved_models\\model_epoch_26_loss_0.0524.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0536 - val_loss: 0.0491\n",
      "Epoch 27/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0502\n",
      "Epoch 27: saving model to saved_models\\model_epoch_27_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0504 - val_loss: 0.0491\n",
      "Epoch 28/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0524\n",
      "Epoch 28: saving model to saved_models\\model_epoch_28_loss_0.0535.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0525 - val_loss: 0.0491\n",
      "Epoch 29/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0522\n",
      "Epoch 29: saving model to saved_models\\model_epoch_29_loss_0.0522.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0522 - val_loss: 0.0491\n",
      "Epoch 30/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0506\n",
      "Epoch 30: saving model to saved_models\\model_epoch_30_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0508 - val_loss: 0.0491\n",
      "Epoch 31/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0515\n",
      "Epoch 31: saving model to saved_models\\model_epoch_31_loss_0.0524.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0516 - val_loss: 0.0491\n",
      "Epoch 32/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0529\n",
      "Epoch 32: saving model to saved_models\\model_epoch_32_loss_0.0522.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0528 - val_loss: 0.0491\n",
      "Epoch 33/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0502\n",
      "Epoch 33: saving model to saved_models\\model_epoch_33_loss_0.0531.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0504 - val_loss: 0.0491\n",
      "Epoch 34/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0529\n",
      "Epoch 34: saving model to saved_models\\model_epoch_34_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0528 - val_loss: 0.0491\n",
      "Epoch 35/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0518\n",
      "Epoch 35: saving model to saved_models\\model_epoch_35_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0518 - val_loss: 0.0491\n",
      "Epoch 36/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0565\n",
      "Epoch 36: saving model to saved_models\\model_epoch_36_loss_0.0525.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0556 - val_loss: 0.0491\n",
      "Epoch 37/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0481\n",
      "Epoch 37: saving model to saved_models\\model_epoch_37_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0486 - val_loss: 0.0491\n",
      "Epoch 38/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0545\n",
      "Epoch 38: saving model to saved_models\\model_epoch_38_loss_0.0536.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0544 - val_loss: 0.0491\n",
      "Epoch 39/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0532\n",
      "Epoch 39: saving model to saved_models\\model_epoch_39_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0530 - val_loss: 0.0490\n",
      "Epoch 40/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0524\n",
      "Epoch 40: saving model to saved_models\\model_epoch_40_loss_0.0525.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0524 - val_loss: 0.0491\n",
      "Epoch 41/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0514\n",
      "Epoch 41: saving model to saved_models\\model_epoch_41_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0514 - val_loss: 0.0491\n",
      "Epoch 42/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0540\n",
      "Epoch 42: saving model to saved_models\\model_epoch_42_loss_0.0526.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0539 - val_loss: 0.0491\n",
      "Epoch 43/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0521\n",
      "Epoch 43: saving model to saved_models\\model_epoch_43_loss_0.0524.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0521 - val_loss: 0.0491\n",
      "Epoch 44/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0513\n",
      "Epoch 44: saving model to saved_models\\model_epoch_44_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0513 - val_loss: 0.0491\n",
      "Epoch 45/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0514\n",
      "Epoch 45: saving model to saved_models\\model_epoch_45_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0515 - val_loss: 0.0491\n",
      "Epoch 46/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0499\n",
      "Epoch 46: saving model to saved_models\\model_epoch_46_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0499 - val_loss: 0.0491\n",
      "Epoch 47/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0508\n",
      "Epoch 47: saving model to saved_models\\model_epoch_47_loss_0.0522.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0511 - val_loss: 0.0491\n",
      "Epoch 48/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0553\n",
      "Epoch 48: saving model to saved_models\\model_epoch_48_loss_0.0531.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0549 - val_loss: 0.0491\n",
      "Epoch 49/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0527\n",
      "Epoch 49: saving model to saved_models\\model_epoch_49_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0524 - val_loss: 0.0490\n",
      "Epoch 50/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0528\n",
      "Epoch 50: saving model to saved_models\\model_epoch_50_loss_0.0524.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0528 - val_loss: 0.0490\n",
      "Epoch 51/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0497\n",
      "Epoch 51: saving model to saved_models\\model_epoch_51_loss_0.0524.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0499 - val_loss: 0.0490\n",
      "Epoch 52/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0505\n",
      "Epoch 52: saving model to saved_models\\model_epoch_52_loss_0.0522.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0506 - val_loss: 0.0490\n",
      "Epoch 53/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0500\n",
      "Epoch 53: saving model to saved_models\\model_epoch_53_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0502 - val_loss: 0.0490\n",
      "Epoch 54/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0550\n",
      "Epoch 54: saving model to saved_models\\model_epoch_54_loss_0.0527.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0547 - val_loss: 0.0490\n",
      "Epoch 55/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0517\n",
      "Epoch 55: saving model to saved_models\\model_epoch_55_loss_0.0526.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0519 - val_loss: 0.0490\n",
      "Epoch 56/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0510\n",
      "Epoch 56: saving model to saved_models\\model_epoch_56_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0511 - val_loss: 0.0490\n",
      "Epoch 57/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0510\n",
      "Epoch 57: saving model to saved_models\\model_epoch_57_loss_0.0525.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0511 - val_loss: 0.0490\n",
      "Epoch 58/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0533\n",
      "Epoch 58: saving model to saved_models\\model_epoch_58_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0528 - val_loss: 0.0491\n",
      "Epoch 59/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0534\n",
      "Epoch 59: saving model to saved_models\\model_epoch_59_loss_0.0527.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0533 - val_loss: 0.0491\n",
      "Epoch 60/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0490\n",
      "Epoch 60: saving model to saved_models\\model_epoch_60_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0494 - val_loss: 0.0491\n",
      "Epoch 61/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0524\n",
      "Epoch 61: saving model to saved_models\\model_epoch_61_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0524 - val_loss: 0.0491\n",
      "Epoch 62/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0535\n",
      "Epoch 62: saving model to saved_models\\model_epoch_62_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0532 - val_loss: 0.0491\n",
      "Epoch 63/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0518\n",
      "Epoch 63: saving model to saved_models\\model_epoch_63_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0517 - val_loss: 0.0491\n",
      "Epoch 64/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0515\n",
      "Epoch 64: saving model to saved_models\\model_epoch_64_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0516 - val_loss: 0.0491\n",
      "Epoch 65/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0511\n",
      "Epoch 65: saving model to saved_models\\model_epoch_65_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0511 - val_loss: 0.0491\n",
      "Epoch 66/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0532\n",
      "Epoch 66: saving model to saved_models\\model_epoch_66_loss_0.0526.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0531 - val_loss: 0.0491\n",
      "Epoch 67/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0494\n",
      "Epoch 67: saving model to saved_models\\model_epoch_67_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0499 - val_loss: 0.0491\n",
      "Epoch 68/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0508\n",
      "Epoch 68: saving model to saved_models\\model_epoch_68_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0508 - val_loss: 0.0491\n",
      "Epoch 69/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0514\n",
      "Epoch 69: saving model to saved_models\\model_epoch_69_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0514 - val_loss: 0.0490\n",
      "Epoch 70/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0499\n",
      "Epoch 70: saving model to saved_models\\model_epoch_70_loss_0.0530.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0502 - val_loss: 0.0490\n",
      "Epoch 71/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0484\n",
      "Epoch 71: saving model to saved_models\\model_epoch_71_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0488 - val_loss: 0.0490\n",
      "Epoch 72/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0521\n",
      "Epoch 72: saving model to saved_models\\model_epoch_72_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0520 - val_loss: 0.0490\n",
      "Epoch 73/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0503\n",
      "Epoch 73: saving model to saved_models\\model_epoch_73_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0504 - val_loss: 0.0490\n",
      "Epoch 74/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0530\n",
      "Epoch 74: saving model to saved_models\\model_epoch_74_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0529 - val_loss: 0.0490\n",
      "Epoch 75/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0536\n",
      "Epoch 75: saving model to saved_models\\model_epoch_75_loss_0.0522.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0535 - val_loss: 0.0490\n",
      "Epoch 76/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0519\n",
      "Epoch 76: saving model to saved_models\\model_epoch_76_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0517 - val_loss: 0.0490\n",
      "Epoch 77/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0519\n",
      "Epoch 77: saving model to saved_models\\model_epoch_77_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0518 - val_loss: 0.0490\n",
      "Epoch 78/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0482\n",
      "Epoch 78: saving model to saved_models\\model_epoch_78_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0485 - val_loss: 0.0491\n",
      "Epoch 79/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0513\n",
      "Epoch 79: saving model to saved_models\\model_epoch_79_loss_0.0526.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0516 - val_loss: 0.0491\n",
      "Epoch 80/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0528\n",
      "Epoch 80: saving model to saved_models\\model_epoch_80_loss_0.0527.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0527 - val_loss: 0.0491\n",
      "Epoch 81/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0558\n",
      "Epoch 81: saving model to saved_models\\model_epoch_81_loss_0.0523.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0553 - val_loss: 0.0490\n",
      "Epoch 82/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0530\n",
      "Epoch 82: saving model to saved_models\\model_epoch_82_loss_0.0529.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0529 - val_loss: 0.0490\n",
      "Epoch 83/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0518\n",
      "Epoch 83: saving model to saved_models\\model_epoch_83_loss_0.0531.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0519 - val_loss: 0.0490\n",
      "Epoch 84/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0493\n",
      "Epoch 84: saving model to saved_models\\model_epoch_84_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0497 - val_loss: 0.0490\n",
      "Epoch 85/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0526\n",
      "Epoch 85: saving model to saved_models\\model_epoch_85_loss_0.0526.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0526 - val_loss: 0.0490\n",
      "Epoch 86/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0554\n",
      "Epoch 86: saving model to saved_models\\model_epoch_86_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0549 - val_loss: 0.0490\n",
      "Epoch 87/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0545\n",
      "Epoch 87: saving model to saved_models\\model_epoch_87_loss_0.0522.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0541 - val_loss: 0.0489\n",
      "Epoch 88/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0511\n",
      "Epoch 88: saving model to saved_models\\model_epoch_88_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0512 - val_loss: 0.0489\n",
      "Epoch 89/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0524\n",
      "Epoch 89: saving model to saved_models\\model_epoch_89_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0523 - val_loss: 0.0489\n",
      "Epoch 90/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0552\n",
      "Epoch 90: saving model to saved_models\\model_epoch_90_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0546 - val_loss: 0.0489\n",
      "Epoch 91/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0543\n",
      "Epoch 91: saving model to saved_models\\model_epoch_91_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0539 - val_loss: 0.0489\n",
      "Epoch 92/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0511\n",
      "Epoch 92: saving model to saved_models\\model_epoch_92_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0512 - val_loss: 0.0490\n",
      "Epoch 93/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0498\n",
      "Epoch 93: saving model to saved_models\\model_epoch_93_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0499 - val_loss: 0.0489\n",
      "Epoch 94/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0517\n",
      "Epoch 94: saving model to saved_models\\model_epoch_94_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0517 - val_loss: 0.0490\n",
      "Epoch 95/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0527\n",
      "Epoch 95: saving model to saved_models\\model_epoch_95_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0525 - val_loss: 0.0490\n",
      "Epoch 96/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0541\n",
      "Epoch 96: saving model to saved_models\\model_epoch_96_loss_0.0540.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0541 - val_loss: 0.0489\n",
      "Epoch 97/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0509\n",
      "Epoch 97: saving model to saved_models\\model_epoch_97_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0510 - val_loss: 0.0489\n",
      "Epoch 98/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0522\n",
      "Epoch 98: saving model to saved_models\\model_epoch_98_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0522 - val_loss: 0.0489\n",
      "Epoch 99/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0553\n",
      "Epoch 99: saving model to saved_models\\model_epoch_99_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0547 - val_loss: 0.0489\n",
      "Epoch 100/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0532\n",
      "Epoch 100: saving model to saved_models\\model_epoch_100_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0531 - val_loss: 0.0490\n",
      "Epoch 101/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0550\n",
      "Epoch 101: saving model to saved_models\\model_epoch_101_loss_0.0528.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0547 - val_loss: 0.0489\n",
      "Epoch 102/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0515\n",
      "Epoch 102: saving model to saved_models\\model_epoch_102_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0516 - val_loss: 0.0489\n",
      "Epoch 103/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0550\n",
      "Epoch 103: saving model to saved_models\\model_epoch_103_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0545 - val_loss: 0.0489\n",
      "Epoch 104/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0499\n",
      "Epoch 104: saving model to saved_models\\model_epoch_104_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0502 - val_loss: 0.0490\n",
      "Epoch 105/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0526\n",
      "Epoch 105: saving model to saved_models\\model_epoch_105_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0525 - val_loss: 0.0490\n",
      "Epoch 106/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0486\n",
      "Epoch 106: saving model to saved_models\\model_epoch_106_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0488 - val_loss: 0.0490\n",
      "Epoch 107/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0546\n",
      "Epoch 107: saving model to saved_models\\model_epoch_107_loss_0.0529.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0543 - val_loss: 0.0489\n",
      "Epoch 108/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0543\n",
      "Epoch 108: saving model to saved_models\\model_epoch_108_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0538 - val_loss: 0.0489\n",
      "Epoch 109/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0538\n",
      "Epoch 109: saving model to saved_models\\model_epoch_109_loss_0.0527.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0536 - val_loss: 0.0489\n",
      "Epoch 110/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0531\n",
      "Epoch 110: saving model to saved_models\\model_epoch_110_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0528 - val_loss: 0.0489\n",
      "Epoch 111/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0535\n",
      "Epoch 111: saving model to saved_models\\model_epoch_111_loss_0.0524.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0533 - val_loss: 0.0489\n",
      "Epoch 112/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0540\n",
      "Epoch 112: saving model to saved_models\\model_epoch_112_loss_0.0527.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0538 - val_loss: 0.0489\n",
      "Epoch 113/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0496\n",
      "Epoch 113: saving model to saved_models\\model_epoch_113_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0498 - val_loss: 0.0490\n",
      "Epoch 114/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0523\n",
      "Epoch 114: saving model to saved_models\\model_epoch_114_loss_0.0529.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0524 - val_loss: 0.0489\n",
      "Epoch 115/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0531\n",
      "Epoch 115: saving model to saved_models\\model_epoch_115_loss_0.0525.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0530 - val_loss: 0.0489\n",
      "Epoch 116/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0518\n",
      "Epoch 116: saving model to saved_models\\model_epoch_116_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0519 - val_loss: 0.0489\n",
      "Epoch 117/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0543\n",
      "Epoch 117: saving model to saved_models\\model_epoch_117_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0539 - val_loss: 0.0489\n",
      "Epoch 118/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0518\n",
      "Epoch 118: saving model to saved_models\\model_epoch_118_loss_0.0527.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0520 - val_loss: 0.0489\n",
      "Epoch 119/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0499\n",
      "Epoch 119: saving model to saved_models\\model_epoch_119_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0502 - val_loss: 0.0489\n",
      "Epoch 120/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0545\n",
      "Epoch 120: saving model to saved_models\\model_epoch_120_loss_0.0522.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0543 - val_loss: 0.0489\n",
      "Epoch 121/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0518\n",
      "Epoch 121: saving model to saved_models\\model_epoch_121_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0518 - val_loss: 0.0489\n",
      "Epoch 122/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0521\n",
      "Epoch 122: saving model to saved_models\\model_epoch_122_loss_0.0523.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0521 - val_loss: 0.0489\n",
      "Epoch 123/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0483\n",
      "Epoch 123: saving model to saved_models\\model_epoch_123_loss_0.0527.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0490 - val_loss: 0.0489\n",
      "Epoch 124/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0519\n",
      "Epoch 124: saving model to saved_models\\model_epoch_124_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0517 - val_loss: 0.0489\n",
      "Epoch 125/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0490\n",
      "Epoch 125: saving model to saved_models\\model_epoch_125_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0495 - val_loss: 0.0489\n",
      "Epoch 126/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0517\n",
      "Epoch 126: saving model to saved_models\\model_epoch_126_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0517 - val_loss: 0.0489\n",
      "Epoch 127/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0500\n",
      "Epoch 127: saving model to saved_models\\model_epoch_127_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0502 - val_loss: 0.0489\n",
      "Epoch 128/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0540\n",
      "Epoch 128: saving model to saved_models\\model_epoch_128_loss_0.0524.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0538 - val_loss: 0.0489\n",
      "Epoch 129/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0503\n",
      "Epoch 129: saving model to saved_models\\model_epoch_129_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0506 - val_loss: 0.0489\n",
      "Epoch 130/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0529\n",
      "Epoch 130: saving model to saved_models\\model_epoch_130_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0527 - val_loss: 0.0488\n",
      "Epoch 131/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0509\n",
      "Epoch 131: saving model to saved_models\\model_epoch_131_loss_0.0522.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0511 - val_loss: 0.0488\n",
      "Epoch 132/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0507\n",
      "Epoch 132: saving model to saved_models\\model_epoch_132_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0508 - val_loss: 0.0488\n",
      "Epoch 133/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0567\n",
      "Epoch 133: saving model to saved_models\\model_epoch_133_loss_0.0531.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0562 - val_loss: 0.0488\n",
      "Epoch 134/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0544\n",
      "Epoch 134: saving model to saved_models\\model_epoch_134_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0542 - val_loss: 0.0488\n",
      "Epoch 135/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0507\n",
      "Epoch 135: saving model to saved_models\\model_epoch_135_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0508 - val_loss: 0.0488\n",
      "Epoch 136/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0519\n",
      "Epoch 136: saving model to saved_models\\model_epoch_136_loss_0.0525.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0521 - val_loss: 0.0488\n",
      "Epoch 137/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0532\n",
      "Epoch 137: saving model to saved_models\\model_epoch_137_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0530 - val_loss: 0.0488\n",
      "Epoch 138/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0521\n",
      "Epoch 138: saving model to saved_models\\model_epoch_138_loss_0.0522.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0521 - val_loss: 0.0488\n",
      "Epoch 139/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0530\n",
      "Epoch 139: saving model to saved_models\\model_epoch_139_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0526 - val_loss: 0.0488\n",
      "Epoch 140/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0477\n",
      "Epoch 140: saving model to saved_models\\model_epoch_140_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0482 - val_loss: 0.0488\n",
      "Epoch 141/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0490\n",
      "Epoch 141: saving model to saved_models\\model_epoch_141_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0493 - val_loss: 0.0488\n",
      "Epoch 142/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0493\n",
      "Epoch 142: saving model to saved_models\\model_epoch_142_loss_0.0523.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0498 - val_loss: 0.0488\n",
      "Epoch 143/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0488\n",
      "Epoch 143: saving model to saved_models\\model_epoch_143_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0493 - val_loss: 0.0488\n",
      "Epoch 144/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0511\n",
      "Epoch 144: saving model to saved_models\\model_epoch_144_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0512 - val_loss: 0.0488\n",
      "Epoch 145/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0483\n",
      "Epoch 145: saving model to saved_models\\model_epoch_145_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0489 - val_loss: 0.0488\n",
      "Epoch 146/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0503\n",
      "Epoch 146: saving model to saved_models\\model_epoch_146_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0504 - val_loss: 0.0488\n",
      "Epoch 147/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0552\n",
      "Epoch 147: saving model to saved_models\\model_epoch_147_loss_0.0534.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0549 - val_loss: 0.0488\n",
      "Epoch 148/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0514\n",
      "Epoch 148: saving model to saved_models\\model_epoch_148_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0514 - val_loss: 0.0488\n",
      "Epoch 149/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0526\n",
      "Epoch 149: saving model to saved_models\\model_epoch_149_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0525 - val_loss: 0.0488\n",
      "Epoch 150/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0501\n",
      "Epoch 150: saving model to saved_models\\model_epoch_150_loss_0.0525.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0505 - val_loss: 0.0488\n",
      "Epoch 151/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0517\n",
      "Epoch 151: saving model to saved_models\\model_epoch_151_loss_0.0526.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0518 - val_loss: 0.0488\n",
      "Epoch 152/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0533\n",
      "Epoch 152: saving model to saved_models\\model_epoch_152_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0532 - val_loss: 0.0489\n",
      "Epoch 153/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0531\n",
      "Epoch 153: saving model to saved_models\\model_epoch_153_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0529 - val_loss: 0.0489\n",
      "Epoch 154/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0547\n",
      "Epoch 154: saving model to saved_models\\model_epoch_154_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0542 - val_loss: 0.0489\n",
      "Epoch 155/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0515\n",
      "Epoch 155: saving model to saved_models\\model_epoch_155_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0515 - val_loss: 0.0489\n",
      "Epoch 156/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0484\n",
      "Epoch 156: saving model to saved_models\\model_epoch_156_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0486 - val_loss: 0.0489\n",
      "Epoch 157/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0516\n",
      "Epoch 157: saving model to saved_models\\model_epoch_157_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0517 - val_loss: 0.0489\n",
      "Epoch 158/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0530\n",
      "Epoch 158: saving model to saved_models\\model_epoch_158_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0529 - val_loss: 0.0489\n",
      "Epoch 159/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0554\n",
      "Epoch 159: saving model to saved_models\\model_epoch_159_loss_0.0526.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0549 - val_loss: 0.0489\n",
      "Epoch 160/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0522\n",
      "Epoch 160: saving model to saved_models\\model_epoch_160_loss_0.0524.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0522 - val_loss: 0.0489\n",
      "Epoch 161/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0512\n",
      "Epoch 161: saving model to saved_models\\model_epoch_161_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0513 - val_loss: 0.0489\n",
      "Epoch 162/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0495\n",
      "Epoch 162: saving model to saved_models\\model_epoch_162_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0499 - val_loss: 0.0489\n",
      "Epoch 163/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0528\n",
      "Epoch 163: saving model to saved_models\\model_epoch_163_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0527 - val_loss: 0.0489\n",
      "Epoch 164/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0488\n",
      "Epoch 164: saving model to saved_models\\model_epoch_164_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0490 - val_loss: 0.0489\n",
      "Epoch 165/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0517\n",
      "Epoch 165: saving model to saved_models\\model_epoch_165_loss_0.0526.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0519 - val_loss: 0.0489\n",
      "Epoch 166/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0492\n",
      "Epoch 166: saving model to saved_models\\model_epoch_166_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0494 - val_loss: 0.0489\n",
      "Epoch 167/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0504\n",
      "Epoch 167: saving model to saved_models\\model_epoch_167_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0506 - val_loss: 0.0489\n",
      "Epoch 168/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0491\n",
      "Epoch 168: saving model to saved_models\\model_epoch_168_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0495 - val_loss: 0.0489\n",
      "Epoch 169/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0538\n",
      "Epoch 169: saving model to saved_models\\model_epoch_169_loss_0.0526.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0536 - val_loss: 0.0489\n",
      "Epoch 170/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0495\n",
      "Epoch 170: saving model to saved_models\\model_epoch_170_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0497 - val_loss: 0.0489\n",
      "Epoch 171/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0520\n",
      "Epoch 171: saving model to saved_models\\model_epoch_171_loss_0.0533.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0522 - val_loss: 0.0489\n",
      "Epoch 172/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0492\n",
      "Epoch 172: saving model to saved_models\\model_epoch_172_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0495 - val_loss: 0.0489\n",
      "Epoch 173/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0536\n",
      "Epoch 173: saving model to saved_models\\model_epoch_173_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0535 - val_loss: 0.0489\n",
      "Epoch 174/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0485\n",
      "Epoch 174: saving model to saved_models\\model_epoch_174_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0490 - val_loss: 0.0489\n",
      "Epoch 175/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0518\n",
      "Epoch 175: saving model to saved_models\\model_epoch_175_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0518 - val_loss: 0.0489\n",
      "Epoch 176/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0492\n",
      "Epoch 176: saving model to saved_models\\model_epoch_176_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0497 - val_loss: 0.0489\n",
      "Epoch 177/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0508\n",
      "Epoch 177: saving model to saved_models\\model_epoch_177_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0509 - val_loss: 0.0488\n",
      "Epoch 178/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0504\n",
      "Epoch 178: saving model to saved_models\\model_epoch_178_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0505 - val_loss: 0.0488\n",
      "Epoch 179/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0488\n",
      "Epoch 179: saving model to saved_models\\model_epoch_179_loss_0.0524.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0494 - val_loss: 0.0488\n",
      "Epoch 180/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0515\n",
      "Epoch 180: saving model to saved_models\\model_epoch_180_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0514 - val_loss: 0.0488\n",
      "Epoch 181/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0510\n",
      "Epoch 181: saving model to saved_models\\model_epoch_181_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0510 - val_loss: 0.0488\n",
      "Epoch 182/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0484\n",
      "Epoch 182: saving model to saved_models\\model_epoch_182_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0487 - val_loss: 0.0488\n",
      "Epoch 183/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0496\n",
      "Epoch 183: saving model to saved_models\\model_epoch_183_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0498 - val_loss: 0.0488\n",
      "Epoch 184/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0530\n",
      "Epoch 184: saving model to saved_models\\model_epoch_184_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0529 - val_loss: 0.0487\n",
      "Epoch 185/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0543\n",
      "Epoch 185: saving model to saved_models\\model_epoch_185_loss_0.0529.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0541 - val_loss: 0.0488\n",
      "Epoch 186/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0511\n",
      "Epoch 186: saving model to saved_models\\model_epoch_186_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0512 - val_loss: 0.0487\n",
      "Epoch 187/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0536\n",
      "Epoch 187: saving model to saved_models\\model_epoch_187_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0534 - val_loss: 0.0488\n",
      "Epoch 188/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0535\n",
      "Epoch 188: saving model to saved_models\\model_epoch_188_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0533 - val_loss: 0.0487\n",
      "Epoch 189/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0532\n",
      "Epoch 189: saving model to saved_models\\model_epoch_189_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0530 - val_loss: 0.0487\n",
      "Epoch 190/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0522\n",
      "Epoch 190: saving model to saved_models\\model_epoch_190_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0521 - val_loss: 0.0488\n",
      "Epoch 191/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0524\n",
      "Epoch 191: saving model to saved_models\\model_epoch_191_loss_0.0525.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0524 - val_loss: 0.0488\n",
      "Epoch 192/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0519\n",
      "Epoch 192: saving model to saved_models\\model_epoch_192_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0517 - val_loss: 0.0488\n",
      "Epoch 193/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0496\n",
      "Epoch 193: saving model to saved_models\\model_epoch_193_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0499 - val_loss: 0.0488\n",
      "Epoch 194/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0498\n",
      "Epoch 194: saving model to saved_models\\model_epoch_194_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0499 - val_loss: 0.0487\n",
      "Epoch 195/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0486\n",
      "Epoch 195: saving model to saved_models\\model_epoch_195_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0491 - val_loss: 0.0487\n",
      "Epoch 196/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0524\n",
      "Epoch 196: saving model to saved_models\\model_epoch_196_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0523 - val_loss: 0.0487\n",
      "Epoch 197/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0527\n",
      "Epoch 197: saving model to saved_models\\model_epoch_197_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0525 - val_loss: 0.0487\n",
      "Epoch 198/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0538\n",
      "Epoch 198: saving model to saved_models\\model_epoch_198_loss_0.0540.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0538 - val_loss: 0.0487\n",
      "Epoch 199/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0514\n",
      "Epoch 199: saving model to saved_models\\model_epoch_199_loss_0.0528.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0516 - val_loss: 0.0487\n",
      "Epoch 200/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0508\n",
      "Epoch 200: saving model to saved_models\\model_epoch_200_loss_0.0525.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0512 - val_loss: 0.0487\n",
      "Epoch 201/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0533\n",
      "Epoch 201: saving model to saved_models\\model_epoch_201_loss_0.0533.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0533 - val_loss: 0.0486\n",
      "Epoch 202/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0553\n",
      "Epoch 202: saving model to saved_models\\model_epoch_202_loss_0.0523.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0548 - val_loss: 0.0486\n",
      "Epoch 203/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0575\n",
      "Epoch 203: saving model to saved_models\\model_epoch_203_loss_0.0539.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0569 - val_loss: 0.0486\n",
      "Epoch 204/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0524\n",
      "Epoch 204: saving model to saved_models\\model_epoch_204_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0523 - val_loss: 0.0486\n",
      "Epoch 205/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0515\n",
      "Epoch 205: saving model to saved_models\\model_epoch_205_loss_0.0527.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0517 - val_loss: 0.0486\n",
      "Epoch 206/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0523\n",
      "Epoch 206: saving model to saved_models\\model_epoch_206_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0523 - val_loss: 0.0485\n",
      "Epoch 207/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0525\n",
      "Epoch 207: saving model to saved_models\\model_epoch_207_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0524 - val_loss: 0.0485\n",
      "Epoch 208/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0530\n",
      "Epoch 208: saving model to saved_models\\model_epoch_208_loss_0.0522.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0528 - val_loss: 0.0485\n",
      "Epoch 209/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0563\n",
      "Epoch 209: saving model to saved_models\\model_epoch_209_loss_0.0524.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0557 - val_loss: 0.0485\n",
      "Epoch 210/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0522\n",
      "Epoch 210: saving model to saved_models\\model_epoch_210_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0520 - val_loss: 0.0486\n",
      "Epoch 211/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0484\n",
      "Epoch 211: saving model to saved_models\\model_epoch_211_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0487 - val_loss: 0.0486\n",
      "Epoch 212/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0507\n",
      "Epoch 212: saving model to saved_models\\model_epoch_212_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0508 - val_loss: 0.0486\n",
      "Epoch 213/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0509\n",
      "Epoch 213: saving model to saved_models\\model_epoch_213_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0510 - val_loss: 0.0486\n",
      "Epoch 214/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0516\n",
      "Epoch 214: saving model to saved_models\\model_epoch_214_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0516 - val_loss: 0.0486\n",
      "Epoch 215/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0535\n",
      "Epoch 215: saving model to saved_models\\model_epoch_215_loss_0.0529.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0534 - val_loss: 0.0486\n",
      "Epoch 216/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0518\n",
      "Epoch 216: saving model to saved_models\\model_epoch_216_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0517 - val_loss: 0.0486\n",
      "Epoch 217/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0531\n",
      "Epoch 217: saving model to saved_models\\model_epoch_217_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0529 - val_loss: 0.0486\n",
      "Epoch 218/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0518\n",
      "Epoch 218: saving model to saved_models\\model_epoch_218_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0518 - val_loss: 0.0486\n",
      "Epoch 219/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0500\n",
      "Epoch 219: saving model to saved_models\\model_epoch_219_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0501 - val_loss: 0.0486\n",
      "Epoch 220/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0529\n",
      "Epoch 220: saving model to saved_models\\model_epoch_220_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0526 - val_loss: 0.0487\n",
      "Epoch 221/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0528\n",
      "Epoch 221: saving model to saved_models\\model_epoch_221_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0527 - val_loss: 0.0487\n",
      "Epoch 222/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0508\n",
      "Epoch 222: saving model to saved_models\\model_epoch_222_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0508 - val_loss: 0.0487\n",
      "Epoch 223/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0495\n",
      "Epoch 223: saving model to saved_models\\model_epoch_223_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0498 - val_loss: 0.0487\n",
      "Epoch 224/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0512\n",
      "Epoch 224: saving model to saved_models\\model_epoch_224_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0513 - val_loss: 0.0487\n",
      "Epoch 225/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0507\n",
      "Epoch 225: saving model to saved_models\\model_epoch_225_loss_0.0523.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0509 - val_loss: 0.0487\n",
      "Epoch 226/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0522\n",
      "Epoch 226: saving model to saved_models\\model_epoch_226_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0521 - val_loss: 0.0486\n",
      "Epoch 227/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0507\n",
      "Epoch 227: saving model to saved_models\\model_epoch_227_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0508 - val_loss: 0.0486\n",
      "Epoch 228/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0489\n",
      "Epoch 228: saving model to saved_models\\model_epoch_228_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0493 - val_loss: 0.0486\n",
      "Epoch 229/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0523\n",
      "Epoch 229: saving model to saved_models\\model_epoch_229_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0522 - val_loss: 0.0486\n",
      "Epoch 230/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0528\n",
      "Epoch 230: saving model to saved_models\\model_epoch_230_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0526 - val_loss: 0.0486\n",
      "Epoch 231/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0533\n",
      "Epoch 231: saving model to saved_models\\model_epoch_231_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0530 - val_loss: 0.0486\n",
      "Epoch 232/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0527\n",
      "Epoch 232: saving model to saved_models\\model_epoch_232_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0526 - val_loss: 0.0486\n",
      "Epoch 233/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0516\n",
      "Epoch 233: saving model to saved_models\\model_epoch_233_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0516 - val_loss: 0.0486\n",
      "Epoch 234/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0546\n",
      "Epoch 234: saving model to saved_models\\model_epoch_234_loss_0.0528.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0544 - val_loss: 0.0486\n",
      "Epoch 235/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0513\n",
      "Epoch 235: saving model to saved_models\\model_epoch_235_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0513 - val_loss: 0.0486\n",
      "Epoch 236/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0544\n",
      "Epoch 236: saving model to saved_models\\model_epoch_236_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0538 - val_loss: 0.0486\n",
      "Epoch 237/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0501\n",
      "Epoch 237: saving model to saved_models\\model_epoch_237_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0503 - val_loss: 0.0486\n",
      "Epoch 238/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0551\n",
      "Epoch 238: saving model to saved_models\\model_epoch_238_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0548 - val_loss: 0.0487\n",
      "Epoch 239/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0540\n",
      "Epoch 239: saving model to saved_models\\model_epoch_239_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0537 - val_loss: 0.0486\n",
      "Epoch 240/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0501\n",
      "Epoch 240: saving model to saved_models\\model_epoch_240_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0504 - val_loss: 0.0486\n",
      "Epoch 241/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0520\n",
      "Epoch 241: saving model to saved_models\\model_epoch_241_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0520 - val_loss: 0.0486\n",
      "Epoch 242/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0504\n",
      "Epoch 242: saving model to saved_models\\model_epoch_242_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0505 - val_loss: 0.0487\n",
      "Epoch 243/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0539\n",
      "Epoch 243: saving model to saved_models\\model_epoch_243_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0535 - val_loss: 0.0486\n",
      "Epoch 244/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0501\n",
      "Epoch 244: saving model to saved_models\\model_epoch_244_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0504 - val_loss: 0.0486\n",
      "Epoch 245/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0521\n",
      "Epoch 245: saving model to saved_models\\model_epoch_245_loss_0.0525.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0521 - val_loss: 0.0486\n",
      "Epoch 246/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0559\n",
      "Epoch 246: saving model to saved_models\\model_epoch_246_loss_0.0532.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0557 - val_loss: 0.0486\n",
      "Epoch 247/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0496\n",
      "Epoch 247: saving model to saved_models\\model_epoch_247_loss_0.0525.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0500 - val_loss: 0.0486\n",
      "Epoch 248/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0498\n",
      "Epoch 248: saving model to saved_models\\model_epoch_248_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0500 - val_loss: 0.0486\n",
      "Epoch 249/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0510\n",
      "Epoch 249: saving model to saved_models\\model_epoch_249_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0512 - val_loss: 0.0486\n",
      "Epoch 250/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0517\n",
      "Epoch 250: saving model to saved_models\\model_epoch_250_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0517 - val_loss: 0.0486\n",
      "Epoch 251/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0546\n",
      "Epoch 251: saving model to saved_models\\model_epoch_251_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0542 - val_loss: 0.0486\n",
      "Epoch 252/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0522\n",
      "Epoch 252: saving model to saved_models\\model_epoch_252_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0521 - val_loss: 0.0486\n",
      "Epoch 253/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0518\n",
      "Epoch 253: saving model to saved_models\\model_epoch_253_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0517 - val_loss: 0.0487\n",
      "Epoch 254/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0545\n",
      "Epoch 254: saving model to saved_models\\model_epoch_254_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0543 - val_loss: 0.0487\n",
      "Epoch 255/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0508\n",
      "Epoch 255: saving model to saved_models\\model_epoch_255_loss_0.0526.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0511 - val_loss: 0.0487\n",
      "Epoch 256/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0493\n",
      "Epoch 256: saving model to saved_models\\model_epoch_256_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0497 - val_loss: 0.0486\n",
      "Epoch 257/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0498\n",
      "Epoch 257: saving model to saved_models\\model_epoch_257_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0499 - val_loss: 0.0486\n",
      "Epoch 258/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0508\n",
      "Epoch 258: saving model to saved_models\\model_epoch_258_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0510 - val_loss: 0.0486\n",
      "Epoch 259/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0535\n",
      "Epoch 259: saving model to saved_models\\model_epoch_259_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0533 - val_loss: 0.0486\n",
      "Epoch 260/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0510\n",
      "Epoch 260: saving model to saved_models\\model_epoch_260_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0510 - val_loss: 0.0486\n",
      "Epoch 261/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0493\n",
      "Epoch 261: saving model to saved_models\\model_epoch_261_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0494 - val_loss: 0.0486\n",
      "Epoch 262/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0506\n",
      "Epoch 262: saving model to saved_models\\model_epoch_262_loss_0.0526.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0508 - val_loss: 0.0485\n",
      "Epoch 263/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0509\n",
      "Epoch 263: saving model to saved_models\\model_epoch_263_loss_0.0522.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0511 - val_loss: 0.0485\n",
      "Epoch 264/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0542\n",
      "Epoch 264: saving model to saved_models\\model_epoch_264_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0538 - val_loss: 0.0485\n",
      "Epoch 265/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0520\n",
      "Epoch 265: saving model to saved_models\\model_epoch_265_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0520 - val_loss: 0.0485\n",
      "Epoch 266/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0489\n",
      "Epoch 266: saving model to saved_models\\model_epoch_266_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0493 - val_loss: 0.0485\n",
      "Epoch 267/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0509\n",
      "Epoch 267: saving model to saved_models\\model_epoch_267_loss_0.0524.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0511 - val_loss: 0.0486\n",
      "Epoch 268/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0506\n",
      "Epoch 268: saving model to saved_models\\model_epoch_268_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0508 - val_loss: 0.0485\n",
      "Epoch 269/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0492\n",
      "Epoch 269: saving model to saved_models\\model_epoch_269_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0493 - val_loss: 0.0486\n",
      "Epoch 270/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0526\n",
      "Epoch 270: saving model to saved_models\\model_epoch_270_loss_0.0523.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0526 - val_loss: 0.0486\n",
      "Epoch 271/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0508\n",
      "Epoch 271: saving model to saved_models\\model_epoch_271_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0508 - val_loss: 0.0486\n",
      "Epoch 272/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0521\n",
      "Epoch 272: saving model to saved_models\\model_epoch_272_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0520 - val_loss: 0.0486\n",
      "Epoch 273/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0535\n",
      "Epoch 273: saving model to saved_models\\model_epoch_273_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0533 - val_loss: 0.0486\n",
      "Epoch 274/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0509\n",
      "Epoch 274: saving model to saved_models\\model_epoch_274_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0510 - val_loss: 0.0486\n",
      "Epoch 275/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0481\n",
      "Epoch 275: saving model to saved_models\\model_epoch_275_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0483 - val_loss: 0.0486\n",
      "Epoch 276/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0504\n",
      "Epoch 276: saving model to saved_models\\model_epoch_276_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0505 - val_loss: 0.0486\n",
      "Epoch 277/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0507\n",
      "Epoch 277: saving model to saved_models\\model_epoch_277_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0509 - val_loss: 0.0486\n",
      "Epoch 278/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0544\n",
      "Epoch 278: saving model to saved_models\\model_epoch_278_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0539 - val_loss: 0.0486\n",
      "Epoch 279/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0533\n",
      "Epoch 279: saving model to saved_models\\model_epoch_279_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0530 - val_loss: 0.0486\n",
      "Epoch 280/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0513\n",
      "Epoch 280: saving model to saved_models\\model_epoch_280_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0513 - val_loss: 0.0486\n",
      "Epoch 281/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0496\n",
      "Epoch 281: saving model to saved_models\\model_epoch_281_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0499 - val_loss: 0.0486\n",
      "Epoch 282/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0511\n",
      "Epoch 282: saving model to saved_models\\model_epoch_282_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0512 - val_loss: 0.0486\n",
      "Epoch 283/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0544\n",
      "Epoch 283: saving model to saved_models\\model_epoch_283_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0540 - val_loss: 0.0486\n",
      "Epoch 284/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0534\n",
      "Epoch 284: saving model to saved_models\\model_epoch_284_loss_0.0535.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0534 - val_loss: 0.0485\n",
      "Epoch 285/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0495\n",
      "Epoch 285: saving model to saved_models\\model_epoch_285_loss_0.0531.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0498 - val_loss: 0.0485\n",
      "Epoch 286/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0510\n",
      "Epoch 286: saving model to saved_models\\model_epoch_286_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0511 - val_loss: 0.0485\n",
      "Epoch 287/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0510\n",
      "Epoch 287: saving model to saved_models\\model_epoch_287_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0510 - val_loss: 0.0485\n",
      "Epoch 288/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0521\n",
      "Epoch 288: saving model to saved_models\\model_epoch_288_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0520 - val_loss: 0.0485\n",
      "Epoch 289/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0503\n",
      "Epoch 289: saving model to saved_models\\model_epoch_289_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0504 - val_loss: 0.0485\n",
      "Epoch 290/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0518\n",
      "Epoch 290: saving model to saved_models\\model_epoch_290_loss_0.0523.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0519 - val_loss: 0.0485\n",
      "Epoch 291/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0496\n",
      "Epoch 291: saving model to saved_models\\model_epoch_291_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0498 - val_loss: 0.0485\n",
      "Epoch 292/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0505\n",
      "Epoch 292: saving model to saved_models\\model_epoch_292_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0506 - val_loss: 0.0485\n",
      "Epoch 293/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0480\n",
      "Epoch 293: saving model to saved_models\\model_epoch_293_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0485 - val_loss: 0.0485\n",
      "Epoch 294/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0514\n",
      "Epoch 294: saving model to saved_models\\model_epoch_294_loss_0.0524.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0517 - val_loss: 0.0485\n",
      "Epoch 295/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0523\n",
      "Epoch 295: saving model to saved_models\\model_epoch_295_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0522 - val_loss: 0.0485\n",
      "Epoch 296/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0530\n",
      "Epoch 296: saving model to saved_models\\model_epoch_296_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0529 - val_loss: 0.0485\n",
      "Epoch 297/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0493\n",
      "Epoch 297: saving model to saved_models\\model_epoch_297_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0496 - val_loss: 0.0485\n",
      "Epoch 298/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0530\n",
      "Epoch 298: saving model to saved_models\\model_epoch_298_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0526 - val_loss: 0.0485\n",
      "Epoch 299/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0526\n",
      "Epoch 299: saving model to saved_models\\model_epoch_299_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0524 - val_loss: 0.0485\n",
      "Epoch 300/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0510\n",
      "Epoch 300: saving model to saved_models\\model_epoch_300_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0511 - val_loss: 0.0485\n",
      "Epoch 301/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0531\n",
      "Epoch 301: saving model to saved_models\\model_epoch_301_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0529 - val_loss: 0.0485\n",
      "Epoch 302/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0536\n",
      "Epoch 302: saving model to saved_models\\model_epoch_302_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0534 - val_loss: 0.0485\n",
      "Epoch 303/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0498\n",
      "Epoch 303: saving model to saved_models\\model_epoch_303_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0500 - val_loss: 0.0485\n",
      "Epoch 304/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0517\n",
      "Epoch 304: saving model to saved_models\\model_epoch_304_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0517 - val_loss: 0.0485\n",
      "Epoch 305/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0530\n",
      "Epoch 305: saving model to saved_models\\model_epoch_305_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0528 - val_loss: 0.0484\n",
      "Epoch 306/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0498\n",
      "Epoch 306: saving model to saved_models\\model_epoch_306_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0498 - val_loss: 0.0484\n",
      "Epoch 307/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0525\n",
      "Epoch 307: saving model to saved_models\\model_epoch_307_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0525 - val_loss: 0.0484\n",
      "Epoch 308/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0507\n",
      "Epoch 308: saving model to saved_models\\model_epoch_308_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0507 - val_loss: 0.0484\n",
      "Epoch 309/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0524\n",
      "Epoch 309: saving model to saved_models\\model_epoch_309_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0523 - val_loss: 0.0484\n",
      "Epoch 310/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0521\n",
      "Epoch 310: saving model to saved_models\\model_epoch_310_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0520 - val_loss: 0.0484\n",
      "Epoch 311/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0527\n",
      "Epoch 311: saving model to saved_models\\model_epoch_311_loss_0.0525.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0527 - val_loss: 0.0484\n",
      "Epoch 312/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0540\n",
      "Epoch 312: saving model to saved_models\\model_epoch_312_loss_0.0530.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0539 - val_loss: 0.0484\n",
      "Epoch 313/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0518\n",
      "Epoch 313: saving model to saved_models\\model_epoch_313_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0517 - val_loss: 0.0484\n",
      "Epoch 314/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0489\n",
      "Epoch 314: saving model to saved_models\\model_epoch_314_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0494 - val_loss: 0.0484\n",
      "Epoch 315/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0499\n",
      "Epoch 315: saving model to saved_models\\model_epoch_315_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0499 - val_loss: 0.0484\n",
      "Epoch 316/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0522\n",
      "Epoch 316: saving model to saved_models\\model_epoch_316_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0519 - val_loss: 0.0484\n",
      "Epoch 317/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0511\n",
      "Epoch 317: saving model to saved_models\\model_epoch_317_loss_0.0527.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0512 - val_loss: 0.0483\n",
      "Epoch 318/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0481\n",
      "Epoch 318: saving model to saved_models\\model_epoch_318_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0485 - val_loss: 0.0484\n",
      "Epoch 319/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0532\n",
      "Epoch 319: saving model to saved_models\\model_epoch_319_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0529 - val_loss: 0.0484\n",
      "Epoch 320/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0504\n",
      "Epoch 320: saving model to saved_models\\model_epoch_320_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0504 - val_loss: 0.0484\n",
      "Epoch 321/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0496\n",
      "Epoch 321: saving model to saved_models\\model_epoch_321_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0500 - val_loss: 0.0484\n",
      "Epoch 322/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0500\n",
      "Epoch 322: saving model to saved_models\\model_epoch_322_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0501 - val_loss: 0.0484\n",
      "Epoch 323/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0485\n",
      "Epoch 323: saving model to saved_models\\model_epoch_323_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0489 - val_loss: 0.0484\n",
      "Epoch 324/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0492\n",
      "Epoch 324: saving model to saved_models\\model_epoch_324_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0493 - val_loss: 0.0484\n",
      "Epoch 325/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0523\n",
      "Epoch 325: saving model to saved_models\\model_epoch_325_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0522 - val_loss: 0.0485\n",
      "Epoch 326/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0521\n",
      "Epoch 326: saving model to saved_models\\model_epoch_326_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0521 - val_loss: 0.0485\n",
      "Epoch 327/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0518\n",
      "Epoch 327: saving model to saved_models\\model_epoch_327_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0518 - val_loss: 0.0485\n",
      "Epoch 328/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0494\n",
      "Epoch 328: saving model to saved_models\\model_epoch_328_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0497 - val_loss: 0.0485\n",
      "Epoch 329/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0524\n",
      "Epoch 329: saving model to saved_models\\model_epoch_329_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0524 - val_loss: 0.0484\n",
      "Epoch 330/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0520\n",
      "Epoch 330: saving model to saved_models\\model_epoch_330_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0520 - val_loss: 0.0484\n",
      "Epoch 331/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0542\n",
      "Epoch 331: saving model to saved_models\\model_epoch_331_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0540 - val_loss: 0.0485\n",
      "Epoch 332/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0527\n",
      "Epoch 332: saving model to saved_models\\model_epoch_332_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0525 - val_loss: 0.0484\n",
      "Epoch 333/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0513\n",
      "Epoch 333: saving model to saved_models\\model_epoch_333_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0514 - val_loss: 0.0485\n",
      "Epoch 334/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0520\n",
      "Epoch 334: saving model to saved_models\\model_epoch_334_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0518 - val_loss: 0.0485\n",
      "Epoch 335/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0532\n",
      "Epoch 335: saving model to saved_models\\model_epoch_335_loss_0.0523.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0531 - val_loss: 0.0484\n",
      "Epoch 336/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0508\n",
      "Epoch 336: saving model to saved_models\\model_epoch_336_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0507 - val_loss: 0.0485\n",
      "Epoch 337/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0526\n",
      "Epoch 337: saving model to saved_models\\model_epoch_337_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0525 - val_loss: 0.0484\n",
      "Epoch 338/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0495\n",
      "Epoch 338: saving model to saved_models\\model_epoch_338_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0497 - val_loss: 0.0484\n",
      "Epoch 339/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0521\n",
      "Epoch 339: saving model to saved_models\\model_epoch_339_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0521 - val_loss: 0.0484\n",
      "Epoch 340/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0514\n",
      "Epoch 340: saving model to saved_models\\model_epoch_340_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0514 - val_loss: 0.0484\n",
      "Epoch 341/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0527\n",
      "Epoch 341: saving model to saved_models\\model_epoch_341_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0527 - val_loss: 0.0484\n",
      "Epoch 342/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0507\n",
      "Epoch 342: saving model to saved_models\\model_epoch_342_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0508 - val_loss: 0.0484\n",
      "Epoch 343/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0518\n",
      "Epoch 343: saving model to saved_models\\model_epoch_343_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0518 - val_loss: 0.0483\n",
      "Epoch 344/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0533\n",
      "Epoch 344: saving model to saved_models\\model_epoch_344_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0530 - val_loss: 0.0484\n",
      "Epoch 345/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0515\n",
      "Epoch 345: saving model to saved_models\\model_epoch_345_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0515 - val_loss: 0.0484\n",
      "Epoch 346/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0511\n",
      "Epoch 346: saving model to saved_models\\model_epoch_346_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0511 - val_loss: 0.0484\n",
      "Epoch 347/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0517\n",
      "Epoch 347: saving model to saved_models\\model_epoch_347_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0515 - val_loss: 0.0483\n",
      "Epoch 348/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0496\n",
      "Epoch 348: saving model to saved_models\\model_epoch_348_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0498 - val_loss: 0.0483\n",
      "Epoch 349/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0550\n",
      "Epoch 349: saving model to saved_models\\model_epoch_349_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0545 - val_loss: 0.0483\n",
      "Epoch 350/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0527\n",
      "Epoch 350: saving model to saved_models\\model_epoch_350_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0524 - val_loss: 0.0484\n",
      "Epoch 351/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0514\n",
      "Epoch 351: saving model to saved_models\\model_epoch_351_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0513 - val_loss: 0.0484\n",
      "Epoch 352/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0511\n",
      "Epoch 352: saving model to saved_models\\model_epoch_352_loss_0.0527.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0512 - val_loss: 0.0484\n",
      "Epoch 353/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0518\n",
      "Epoch 353: saving model to saved_models\\model_epoch_353_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0518 - val_loss: 0.0484\n",
      "Epoch 354/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0532\n",
      "Epoch 354: saving model to saved_models\\model_epoch_354_loss_0.0526.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0531 - val_loss: 0.0484\n",
      "Epoch 355/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0509\n",
      "Epoch 355: saving model to saved_models\\model_epoch_355_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0509 - val_loss: 0.0484\n",
      "Epoch 356/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0502\n",
      "Epoch 356: saving model to saved_models\\model_epoch_356_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0503 - val_loss: 0.0484\n",
      "Epoch 357/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0542\n",
      "Epoch 357: saving model to saved_models\\model_epoch_357_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0540 - val_loss: 0.0484\n",
      "Epoch 358/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0491\n",
      "Epoch 358: saving model to saved_models\\model_epoch_358_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0494 - val_loss: 0.0483\n",
      "Epoch 359/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0538\n",
      "Epoch 359: saving model to saved_models\\model_epoch_359_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0534 - val_loss: 0.0483\n",
      "Epoch 360/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0521\n",
      "Epoch 360: saving model to saved_models\\model_epoch_360_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0520 - val_loss: 0.0484\n",
      "Epoch 361/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0494\n",
      "Epoch 361: saving model to saved_models\\model_epoch_361_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0498 - val_loss: 0.0483\n",
      "Epoch 362/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0514\n",
      "Epoch 362: saving model to saved_models\\model_epoch_362_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0514 - val_loss: 0.0484\n",
      "Epoch 363/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0500\n",
      "Epoch 363: saving model to saved_models\\model_epoch_363_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0502 - val_loss: 0.0484\n",
      "Epoch 364/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0515\n",
      "Epoch 364: saving model to saved_models\\model_epoch_364_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0513 - val_loss: 0.0484\n",
      "Epoch 365/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0471\n",
      "Epoch 365: saving model to saved_models\\model_epoch_365_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0476 - val_loss: 0.0483\n",
      "Epoch 366/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0474\n",
      "Epoch 366: saving model to saved_models\\model_epoch_366_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0480 - val_loss: 0.0483\n",
      "Epoch 367/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0494\n",
      "Epoch 367: saving model to saved_models\\model_epoch_367_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0496 - val_loss: 0.0483\n",
      "Epoch 368/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0501\n",
      "Epoch 368: saving model to saved_models\\model_epoch_368_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0503 - val_loss: 0.0483\n",
      "Epoch 369/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0508\n",
      "Epoch 369: saving model to saved_models\\model_epoch_369_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0510 - val_loss: 0.0483\n",
      "Epoch 370/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0518\n",
      "Epoch 370: saving model to saved_models\\model_epoch_370_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0519 - val_loss: 0.0483\n",
      "Epoch 371/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0552\n",
      "Epoch 371: saving model to saved_models\\model_epoch_371_loss_0.0522.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0549 - val_loss: 0.0483\n",
      "Epoch 372/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0532\n",
      "Epoch 372: saving model to saved_models\\model_epoch_372_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0529 - val_loss: 0.0483\n",
      "Epoch 373/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0523\n",
      "Epoch 373: saving model to saved_models\\model_epoch_373_loss_0.0524.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0523 - val_loss: 0.0483\n",
      "Epoch 374/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0528\n",
      "Epoch 374: saving model to saved_models\\model_epoch_374_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0525 - val_loss: 0.0483\n",
      "Epoch 375/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0505\n",
      "Epoch 375: saving model to saved_models\\model_epoch_375_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0506 - val_loss: 0.0483\n",
      "Epoch 376/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0505\n",
      "Epoch 376: saving model to saved_models\\model_epoch_376_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0506 - val_loss: 0.0484\n",
      "Epoch 377/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0504\n",
      "Epoch 377: saving model to saved_models\\model_epoch_377_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0505 - val_loss: 0.0483\n",
      "Epoch 378/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0512\n",
      "Epoch 378: saving model to saved_models\\model_epoch_378_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0514 - val_loss: 0.0483\n",
      "Epoch 379/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0508\n",
      "Epoch 379: saving model to saved_models\\model_epoch_379_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0509 - val_loss: 0.0483\n",
      "Epoch 380/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0517\n",
      "Epoch 380: saving model to saved_models\\model_epoch_380_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0517 - val_loss: 0.0483\n",
      "Epoch 381/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0538\n",
      "Epoch 381: saving model to saved_models\\model_epoch_381_loss_0.0526.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0536 - val_loss: 0.0483\n",
      "Epoch 382/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0522\n",
      "Epoch 382: saving model to saved_models\\model_epoch_382_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0520 - val_loss: 0.0482\n",
      "Epoch 383/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0505\n",
      "Epoch 383: saving model to saved_models\\model_epoch_383_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0505 - val_loss: 0.0483\n",
      "Epoch 384/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0485\n",
      "Epoch 384: saving model to saved_models\\model_epoch_384_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0489 - val_loss: 0.0483\n",
      "Epoch 385/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0531\n",
      "Epoch 385: saving model to saved_models\\model_epoch_385_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0527 - val_loss: 0.0483\n",
      "Epoch 386/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0513\n",
      "Epoch 386: saving model to saved_models\\model_epoch_386_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0512 - val_loss: 0.0483\n",
      "Epoch 387/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0495\n",
      "Epoch 387: saving model to saved_models\\model_epoch_387_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0499 - val_loss: 0.0483\n",
      "Epoch 388/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0538\n",
      "Epoch 388: saving model to saved_models\\model_epoch_388_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0534 - val_loss: 0.0483\n",
      "Epoch 389/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0512\n",
      "Epoch 389: saving model to saved_models\\model_epoch_389_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0512 - val_loss: 0.0483\n",
      "Epoch 390/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0516\n",
      "Epoch 390: saving model to saved_models\\model_epoch_390_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0515 - val_loss: 0.0483\n",
      "Epoch 391/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0474\n",
      "Epoch 391: saving model to saved_models\\model_epoch_391_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0479 - val_loss: 0.0483\n",
      "Epoch 392/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0555\n",
      "Epoch 392: saving model to saved_models\\model_epoch_392_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0549 - val_loss: 0.0483\n",
      "Epoch 393/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0477\n",
      "Epoch 393: saving model to saved_models\\model_epoch_393_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0483 - val_loss: 0.0483\n",
      "Epoch 394/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0490\n",
      "Epoch 394: saving model to saved_models\\model_epoch_394_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0492 - val_loss: 0.0483\n",
      "Epoch 395/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0520\n",
      "Epoch 395: saving model to saved_models\\model_epoch_395_loss_0.0522.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0520 - val_loss: 0.0483\n",
      "Epoch 396/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0506\n",
      "Epoch 396: saving model to saved_models\\model_epoch_396_loss_0.0531.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0511 - val_loss: 0.0483\n",
      "Epoch 397/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0510\n",
      "Epoch 397: saving model to saved_models\\model_epoch_397_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0510 - val_loss: 0.0483\n",
      "Epoch 398/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0499\n",
      "Epoch 398: saving model to saved_models\\model_epoch_398_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0501 - val_loss: 0.0483\n",
      "Epoch 399/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0445\n",
      "Epoch 399: saving model to saved_models\\model_epoch_399_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0454 - val_loss: 0.0483\n",
      "Epoch 400/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0525\n",
      "Epoch 400: saving model to saved_models\\model_epoch_400_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0524 - val_loss: 0.0483\n",
      "Epoch 401/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0515\n",
      "Epoch 401: saving model to saved_models\\model_epoch_401_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0515 - val_loss: 0.0483\n",
      "Epoch 402/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0523\n",
      "Epoch 402: saving model to saved_models\\model_epoch_402_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0521 - val_loss: 0.0483\n",
      "Epoch 403/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0501\n",
      "Epoch 403: saving model to saved_models\\model_epoch_403_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0502 - val_loss: 0.0483\n",
      "Epoch 404/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0504\n",
      "Epoch 404: saving model to saved_models\\model_epoch_404_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0504 - val_loss: 0.0483\n",
      "Epoch 405/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0509\n",
      "Epoch 405: saving model to saved_models\\model_epoch_405_loss_0.0523.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0511 - val_loss: 0.0483\n",
      "Epoch 406/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0525\n",
      "Epoch 406: saving model to saved_models\\model_epoch_406_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0524 - val_loss: 0.0483\n",
      "Epoch 407/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0518\n",
      "Epoch 407: saving model to saved_models\\model_epoch_407_loss_0.0525.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0519 - val_loss: 0.0483\n",
      "Epoch 408/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0528\n",
      "Epoch 408: saving model to saved_models\\model_epoch_408_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0527 - val_loss: 0.0483\n",
      "Epoch 409/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0530\n",
      "Epoch 409: saving model to saved_models\\model_epoch_409_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0528 - val_loss: 0.0483\n",
      "Epoch 410/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0511\n",
      "Epoch 410: saving model to saved_models\\model_epoch_410_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0510 - val_loss: 0.0483\n",
      "Epoch 411/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0537\n",
      "Epoch 411: saving model to saved_models\\model_epoch_411_loss_0.0532.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0536 - val_loss: 0.0483\n",
      "Epoch 412/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0527\n",
      "Epoch 412: saving model to saved_models\\model_epoch_412_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0525 - val_loss: 0.0483\n",
      "Epoch 413/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0519\n",
      "Epoch 413: saving model to saved_models\\model_epoch_413_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0519 - val_loss: 0.0483\n",
      "Epoch 414/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0531\n",
      "Epoch 414: saving model to saved_models\\model_epoch_414_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0529 - val_loss: 0.0483\n",
      "Epoch 415/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0507\n",
      "Epoch 415: saving model to saved_models\\model_epoch_415_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0508 - val_loss: 0.0483\n",
      "Epoch 416/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0535\n",
      "Epoch 416: saving model to saved_models\\model_epoch_416_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0532 - val_loss: 0.0483\n",
      "Epoch 417/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0508\n",
      "Epoch 417: saving model to saved_models\\model_epoch_417_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0508 - val_loss: 0.0483\n",
      "Epoch 418/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0514\n",
      "Epoch 418: saving model to saved_models\\model_epoch_418_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0514 - val_loss: 0.0483\n",
      "Epoch 419/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0525\n",
      "Epoch 419: saving model to saved_models\\model_epoch_419_loss_0.0496.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0521 - val_loss: 0.0482\n",
      "Epoch 420/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0514\n",
      "Epoch 420: saving model to saved_models\\model_epoch_420_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0512 - val_loss: 0.0482\n",
      "Epoch 421/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0502\n",
      "Epoch 421: saving model to saved_models\\model_epoch_421_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0503 - val_loss: 0.0482\n",
      "Epoch 422/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0550\n",
      "Epoch 422: saving model to saved_models\\model_epoch_422_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0545 - val_loss: 0.0482\n",
      "Epoch 423/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0511\n",
      "Epoch 423: saving model to saved_models\\model_epoch_423_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0510 - val_loss: 0.0482\n",
      "Epoch 424/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0467\n",
      "Epoch 424: saving model to saved_models\\model_epoch_424_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0474 - val_loss: 0.0482\n",
      "Epoch 425/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0523\n",
      "Epoch 425: saving model to saved_models\\model_epoch_425_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0521 - val_loss: 0.0482\n",
      "Epoch 426/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0488\n",
      "Epoch 426: saving model to saved_models\\model_epoch_426_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0492 - val_loss: 0.0482\n",
      "Epoch 427/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0504\n",
      "Epoch 427: saving model to saved_models\\model_epoch_427_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0506 - val_loss: 0.0482\n",
      "Epoch 428/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0517\n",
      "Epoch 428: saving model to saved_models\\model_epoch_428_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0516 - val_loss: 0.0483\n",
      "Epoch 429/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0514\n",
      "Epoch 429: saving model to saved_models\\model_epoch_429_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0515 - val_loss: 0.0482\n",
      "Epoch 430/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0529\n",
      "Epoch 430: saving model to saved_models\\model_epoch_430_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0526 - val_loss: 0.0482\n",
      "Epoch 431/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0526\n",
      "Epoch 431: saving model to saved_models\\model_epoch_431_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0523 - val_loss: 0.0483\n",
      "Epoch 432/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0496\n",
      "Epoch 432: saving model to saved_models\\model_epoch_432_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0498 - val_loss: 0.0482\n",
      "Epoch 433/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0518\n",
      "Epoch 433: saving model to saved_models\\model_epoch_433_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0518 - val_loss: 0.0482\n",
      "Epoch 434/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0543\n",
      "Epoch 434: saving model to saved_models\\model_epoch_434_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0541 - val_loss: 0.0482\n",
      "Epoch 435/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0490\n",
      "Epoch 435: saving model to saved_models\\model_epoch_435_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0490 - val_loss: 0.0482\n",
      "Epoch 436/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0545\n",
      "Epoch 436: saving model to saved_models\\model_epoch_436_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0543 - val_loss: 0.0482\n",
      "Epoch 437/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0540\n",
      "Epoch 437: saving model to saved_models\\model_epoch_437_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0539 - val_loss: 0.0482\n",
      "Epoch 438/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0498\n",
      "Epoch 438: saving model to saved_models\\model_epoch_438_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0499 - val_loss: 0.0482\n",
      "Epoch 439/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0549\n",
      "Epoch 439: saving model to saved_models\\model_epoch_439_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0544 - val_loss: 0.0482\n",
      "Epoch 440/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0508\n",
      "Epoch 440: saving model to saved_models\\model_epoch_440_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0507 - val_loss: 0.0482\n",
      "Epoch 441/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0506\n",
      "Epoch 441: saving model to saved_models\\model_epoch_441_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0506 - val_loss: 0.0482\n",
      "Epoch 442/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0480\n",
      "Epoch 442: saving model to saved_models\\model_epoch_442_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0482 - val_loss: 0.0482\n",
      "Epoch 443/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0473\n",
      "Epoch 443: saving model to saved_models\\model_epoch_443_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0478 - val_loss: 0.0482\n",
      "Epoch 444/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0527\n",
      "Epoch 444: saving model to saved_models\\model_epoch_444_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0526 - val_loss: 0.0482\n",
      "Epoch 445/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0511\n",
      "Epoch 445: saving model to saved_models\\model_epoch_445_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0512 - val_loss: 0.0482\n",
      "Epoch 446/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0520\n",
      "Epoch 446: saving model to saved_models\\model_epoch_446_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0519 - val_loss: 0.0482\n",
      "Epoch 447/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0532\n",
      "Epoch 447: saving model to saved_models\\model_epoch_447_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0531 - val_loss: 0.0481\n",
      "Epoch 448/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0499\n",
      "Epoch 448: saving model to saved_models\\model_epoch_448_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0502 - val_loss: 0.0482\n",
      "Epoch 449/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0487\n",
      "Epoch 449: saving model to saved_models\\model_epoch_449_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0493 - val_loss: 0.0482\n",
      "Epoch 450/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0549\n",
      "Epoch 450: saving model to saved_models\\model_epoch_450_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0543 - val_loss: 0.0482\n",
      "Epoch 451/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0506\n",
      "Epoch 451: saving model to saved_models\\model_epoch_451_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0508 - val_loss: 0.0481\n",
      "Epoch 452/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0506\n",
      "Epoch 452: saving model to saved_models\\model_epoch_452_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0506 - val_loss: 0.0481\n",
      "Epoch 453/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0508\n",
      "Epoch 453: saving model to saved_models\\model_epoch_453_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0507 - val_loss: 0.0482\n",
      "Epoch 454/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0477\n",
      "Epoch 454: saving model to saved_models\\model_epoch_454_loss_0.0488.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0479 - val_loss: 0.0482\n",
      "Epoch 455/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0530\n",
      "Epoch 455: saving model to saved_models\\model_epoch_455_loss_0.0523.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0529 - val_loss: 0.0482\n",
      "Epoch 456/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0517\n",
      "Epoch 456: saving model to saved_models\\model_epoch_456_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0517 - val_loss: 0.0482\n",
      "Epoch 457/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0496\n",
      "Epoch 457: saving model to saved_models\\model_epoch_457_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0497 - val_loss: 0.0482\n",
      "Epoch 458/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0521\n",
      "Epoch 458: saving model to saved_models\\model_epoch_458_loss_0.0524.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0521 - val_loss: 0.0481\n",
      "Epoch 459/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0514\n",
      "Epoch 459: saving model to saved_models\\model_epoch_459_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0514 - val_loss: 0.0481\n",
      "Epoch 460/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0508\n",
      "Epoch 460: saving model to saved_models\\model_epoch_460_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0509 - val_loss: 0.0481\n",
      "Epoch 461/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0534\n",
      "Epoch 461: saving model to saved_models\\model_epoch_461_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0530 - val_loss: 0.0481\n",
      "Epoch 462/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0551\n",
      "Epoch 462: saving model to saved_models\\model_epoch_462_loss_0.0527.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0547 - val_loss: 0.0481\n",
      "Epoch 463/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0505\n",
      "Epoch 463: saving model to saved_models\\model_epoch_463_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0504 - val_loss: 0.0481\n",
      "Epoch 464/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0521\n",
      "Epoch 464: saving model to saved_models\\model_epoch_464_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0520 - val_loss: 0.0480\n",
      "Epoch 465/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0529\n",
      "Epoch 465: saving model to saved_models\\model_epoch_465_loss_0.0522.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0528 - val_loss: 0.0480\n",
      "Epoch 466/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0523\n",
      "Epoch 466: saving model to saved_models\\model_epoch_466_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0521 - val_loss: 0.0480\n",
      "Epoch 467/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0525\n",
      "Epoch 467: saving model to saved_models\\model_epoch_467_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0523 - val_loss: 0.0480\n",
      "Epoch 468/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0503\n",
      "Epoch 468: saving model to saved_models\\model_epoch_468_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0505 - val_loss: 0.0480\n",
      "Epoch 469/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0473\n",
      "Epoch 469: saving model to saved_models\\model_epoch_469_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0479 - val_loss: 0.0480\n",
      "Epoch 470/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0500\n",
      "Epoch 470: saving model to saved_models\\model_epoch_470_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0502 - val_loss: 0.0480\n",
      "Epoch 471/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0556\n",
      "Epoch 471: saving model to saved_models\\model_epoch_471_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0546 - val_loss: 0.0480\n",
      "Epoch 472/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0525\n",
      "Epoch 472: saving model to saved_models\\model_epoch_472_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0525 - val_loss: 0.0480\n",
      "Epoch 473/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0517\n",
      "Epoch 473: saving model to saved_models\\model_epoch_473_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0517 - val_loss: 0.0481\n",
      "Epoch 474/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0489\n",
      "Epoch 474: saving model to saved_models\\model_epoch_474_loss_0.0493.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0489 - val_loss: 0.0481\n",
      "Epoch 475/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0507\n",
      "Epoch 475: saving model to saved_models\\model_epoch_475_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0507 - val_loss: 0.0481\n",
      "Epoch 476/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0512\n",
      "Epoch 476: saving model to saved_models\\model_epoch_476_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0512 - val_loss: 0.0481\n",
      "Epoch 477/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0516\n",
      "Epoch 477: saving model to saved_models\\model_epoch_477_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0516 - val_loss: 0.0481\n",
      "Epoch 478/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0511\n",
      "Epoch 478: saving model to saved_models\\model_epoch_478_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0510 - val_loss: 0.0481\n",
      "Epoch 479/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0486\n",
      "Epoch 479: saving model to saved_models\\model_epoch_479_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0490 - val_loss: 0.0481\n",
      "Epoch 480/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0512\n",
      "Epoch 480: saving model to saved_models\\model_epoch_480_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0513 - val_loss: 0.0481\n",
      "Epoch 481/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0512\n",
      "Epoch 481: saving model to saved_models\\model_epoch_481_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0512 - val_loss: 0.0481\n",
      "Epoch 482/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0520\n",
      "Epoch 482: saving model to saved_models\\model_epoch_482_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0520 - val_loss: 0.0481\n",
      "Epoch 483/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0551\n",
      "Epoch 483: saving model to saved_models\\model_epoch_483_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0549 - val_loss: 0.0481\n",
      "Epoch 484/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0503\n",
      "Epoch 484: saving model to saved_models\\model_epoch_484_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0505 - val_loss: 0.0481\n",
      "Epoch 485/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0474\n",
      "Epoch 485: saving model to saved_models\\model_epoch_485_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0481 - val_loss: 0.0481\n",
      "Epoch 486/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0502\n",
      "Epoch 486: saving model to saved_models\\model_epoch_486_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0503 - val_loss: 0.0481\n",
      "Epoch 487/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0520\n",
      "Epoch 487: saving model to saved_models\\model_epoch_487_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0519 - val_loss: 0.0481\n",
      "Epoch 488/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0514\n",
      "Epoch 488: saving model to saved_models\\model_epoch_488_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0513 - val_loss: 0.0481\n",
      "Epoch 489/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0496\n",
      "Epoch 489: saving model to saved_models\\model_epoch_489_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0497 - val_loss: 0.0482\n",
      "Epoch 490/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0488\n",
      "Epoch 490: saving model to saved_models\\model_epoch_490_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0489 - val_loss: 0.0482\n",
      "Epoch 491/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0507\n",
      "Epoch 491: saving model to saved_models\\model_epoch_491_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0507 - val_loss: 0.0482\n",
      "Epoch 492/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0486\n",
      "Epoch 492: saving model to saved_models\\model_epoch_492_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0488 - val_loss: 0.0482\n",
      "Epoch 493/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0497\n",
      "Epoch 493: saving model to saved_models\\model_epoch_493_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0498 - val_loss: 0.0482\n",
      "Epoch 494/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0530\n",
      "Epoch 494: saving model to saved_models\\model_epoch_494_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0526 - val_loss: 0.0482\n",
      "Epoch 495/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0538\n",
      "Epoch 495: saving model to saved_models\\model_epoch_495_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0533 - val_loss: 0.0482\n",
      "Epoch 496/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0521\n",
      "Epoch 496: saving model to saved_models\\model_epoch_496_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0520 - val_loss: 0.0481\n",
      "Epoch 497/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0511\n",
      "Epoch 497: saving model to saved_models\\model_epoch_497_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0511 - val_loss: 0.0482\n",
      "Epoch 498/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0510\n",
      "Epoch 498: saving model to saved_models\\model_epoch_498_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0511 - val_loss: 0.0481\n",
      "Epoch 499/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0514\n",
      "Epoch 499: saving model to saved_models\\model_epoch_499_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0513 - val_loss: 0.0481\n",
      "Epoch 500/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0531\n",
      "Epoch 500: saving model to saved_models\\model_epoch_500_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0528 - val_loss: 0.0481\n",
      "Epoch 501/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0501\n",
      "Epoch 501: saving model to saved_models\\model_epoch_501_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0501 - val_loss: 0.0481\n",
      "Epoch 502/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0518\n",
      "Epoch 502: saving model to saved_models\\model_epoch_502_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0517 - val_loss: 0.0481\n",
      "Epoch 503/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0506\n",
      "Epoch 503: saving model to saved_models\\model_epoch_503_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0507 - val_loss: 0.0481\n",
      "Epoch 504/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0485\n",
      "Epoch 504: saving model to saved_models\\model_epoch_504_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0487 - val_loss: 0.0481\n",
      "Epoch 505/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0493\n",
      "Epoch 505: saving model to saved_models\\model_epoch_505_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0496 - val_loss: 0.0480\n",
      "Epoch 506/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0502\n",
      "Epoch 506: saving model to saved_models\\model_epoch_506_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0503 - val_loss: 0.0480\n",
      "Epoch 507/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0525\n",
      "Epoch 507: saving model to saved_models\\model_epoch_507_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0523 - val_loss: 0.0481\n",
      "Epoch 508/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0496\n",
      "Epoch 508: saving model to saved_models\\model_epoch_508_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0499 - val_loss: 0.0481\n",
      "Epoch 509/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0505\n",
      "Epoch 509: saving model to saved_models\\model_epoch_509_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0504 - val_loss: 0.0481\n",
      "Epoch 510/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0515\n",
      "Epoch 510: saving model to saved_models\\model_epoch_510_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0515 - val_loss: 0.0481\n",
      "Epoch 511/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0527\n",
      "Epoch 511: saving model to saved_models\\model_epoch_511_loss_0.0533.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0529 - val_loss: 0.0481\n",
      "Epoch 512/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0482\n",
      "Epoch 512: saving model to saved_models\\model_epoch_512_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0485 - val_loss: 0.0480\n",
      "Epoch 513/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0522\n",
      "Epoch 513: saving model to saved_models\\model_epoch_513_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0521 - val_loss: 0.0480\n",
      "Epoch 514/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0549\n",
      "Epoch 514: saving model to saved_models\\model_epoch_514_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0544 - val_loss: 0.0480\n",
      "Epoch 515/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0507\n",
      "Epoch 515: saving model to saved_models\\model_epoch_515_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0507 - val_loss: 0.0480\n",
      "Epoch 516/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0501\n",
      "Epoch 516: saving model to saved_models\\model_epoch_516_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0503 - val_loss: 0.0480\n",
      "Epoch 517/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0484\n",
      "Epoch 517: saving model to saved_models\\model_epoch_517_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0486 - val_loss: 0.0480\n",
      "Epoch 518/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0465\n",
      "Epoch 518: saving model to saved_models\\model_epoch_518_loss_0.0487.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0468 - val_loss: 0.0480\n",
      "Epoch 519/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0532\n",
      "Epoch 519: saving model to saved_models\\model_epoch_519_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0529 - val_loss: 0.0480\n",
      "Epoch 520/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0524\n",
      "Epoch 520: saving model to saved_models\\model_epoch_520_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0524 - val_loss: 0.0480\n",
      "Epoch 521/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0538\n",
      "Epoch 521: saving model to saved_models\\model_epoch_521_loss_0.0523.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0537 - val_loss: 0.0480\n",
      "Epoch 522/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0511\n",
      "Epoch 522: saving model to saved_models\\model_epoch_522_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0511 - val_loss: 0.0480\n",
      "Epoch 523/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0527\n",
      "Epoch 523: saving model to saved_models\\model_epoch_523_loss_0.0522.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0526 - val_loss: 0.0480\n",
      "Epoch 524/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0520\n",
      "Epoch 524: saving model to saved_models\\model_epoch_524_loss_0.0520.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0520 - val_loss: 0.0480\n",
      "Epoch 525/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0528\n",
      "Epoch 525: saving model to saved_models\\model_epoch_525_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0525 - val_loss: 0.0480\n",
      "Epoch 526/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0500\n",
      "Epoch 526: saving model to saved_models\\model_epoch_526_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0500 - val_loss: 0.0479\n",
      "Epoch 527/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0510\n",
      "Epoch 527: saving model to saved_models\\model_epoch_527_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0511 - val_loss: 0.0479\n",
      "Epoch 528/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0497\n",
      "Epoch 528: saving model to saved_models\\model_epoch_528_loss_0.0522.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0501 - val_loss: 0.0479\n",
      "Epoch 529/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0507\n",
      "Epoch 529: saving model to saved_models\\model_epoch_529_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0511 - val_loss: 0.0479\n",
      "Epoch 530/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0523\n",
      "Epoch 530: saving model to saved_models\\model_epoch_530_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0522 - val_loss: 0.0479\n",
      "Epoch 531/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0520\n",
      "Epoch 531: saving model to saved_models\\model_epoch_531_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0519 - val_loss: 0.0479\n",
      "Epoch 532/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0499\n",
      "Epoch 532: saving model to saved_models\\model_epoch_532_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0499 - val_loss: 0.0479\n",
      "Epoch 533/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0532\n",
      "Epoch 533: saving model to saved_models\\model_epoch_533_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0527 - val_loss: 0.0479\n",
      "Epoch 534/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0517\n",
      "Epoch 534: saving model to saved_models\\model_epoch_534_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0517 - val_loss: 0.0479\n",
      "Epoch 535/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0526\n",
      "Epoch 535: saving model to saved_models\\model_epoch_535_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0524 - val_loss: 0.0479\n",
      "Epoch 536/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0514\n",
      "Epoch 536: saving model to saved_models\\model_epoch_536_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0514 - val_loss: 0.0479\n",
      "Epoch 537/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0515\n",
      "Epoch 537: saving model to saved_models\\model_epoch_537_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0514 - val_loss: 0.0479\n",
      "Epoch 538/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0517\n",
      "Epoch 538: saving model to saved_models\\model_epoch_538_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0516 - val_loss: 0.0479\n",
      "Epoch 539/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0485\n",
      "Epoch 539: saving model to saved_models\\model_epoch_539_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0491 - val_loss: 0.0479\n",
      "Epoch 540/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0550\n",
      "Epoch 540: saving model to saved_models\\model_epoch_540_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0544 - val_loss: 0.0479\n",
      "Epoch 541/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0526\n",
      "Epoch 541: saving model to saved_models\\model_epoch_541_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0523 - val_loss: 0.0479\n",
      "Epoch 542/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0513\n",
      "Epoch 542: saving model to saved_models\\model_epoch_542_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0512 - val_loss: 0.0479\n",
      "Epoch 543/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0511\n",
      "Epoch 543: saving model to saved_models\\model_epoch_543_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0511 - val_loss: 0.0479\n",
      "Epoch 544/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0494\n",
      "Epoch 544: saving model to saved_models\\model_epoch_544_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0494 - val_loss: 0.0479\n",
      "Epoch 545/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0504\n",
      "Epoch 545: saving model to saved_models\\model_epoch_545_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0504 - val_loss: 0.0479\n",
      "Epoch 546/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0500\n",
      "Epoch 546: saving model to saved_models\\model_epoch_546_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0500 - val_loss: 0.0479\n",
      "Epoch 547/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0529\n",
      "Epoch 547: saving model to saved_models\\model_epoch_547_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0527 - val_loss: 0.0479\n",
      "Epoch 548/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0512\n",
      "Epoch 548: saving model to saved_models\\model_epoch_548_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0512 - val_loss: 0.0479\n",
      "Epoch 549/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0522\n",
      "Epoch 549: saving model to saved_models\\model_epoch_549_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0521 - val_loss: 0.0479\n",
      "Epoch 550/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0470\n",
      "Epoch 550: saving model to saved_models\\model_epoch_550_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0476 - val_loss: 0.0479\n",
      "Epoch 551/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0511\n",
      "Epoch 551: saving model to saved_models\\model_epoch_551_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0510 - val_loss: 0.0479\n",
      "Epoch 552/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0505\n",
      "Epoch 552: saving model to saved_models\\model_epoch_552_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0504 - val_loss: 0.0479\n",
      "Epoch 553/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0498\n",
      "Epoch 553: saving model to saved_models\\model_epoch_553_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0500 - val_loss: 0.0479\n",
      "Epoch 554/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0514\n",
      "Epoch 554: saving model to saved_models\\model_epoch_554_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0515 - val_loss: 0.0479\n",
      "Epoch 555/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0516\n",
      "Epoch 555: saving model to saved_models\\model_epoch_555_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0516 - val_loss: 0.0479\n",
      "Epoch 556/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0514\n",
      "Epoch 556: saving model to saved_models\\model_epoch_556_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0514 - val_loss: 0.0479\n",
      "Epoch 557/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0514\n",
      "Epoch 557: saving model to saved_models\\model_epoch_557_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0514 - val_loss: 0.0479\n",
      "Epoch 558/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0478\n",
      "Epoch 558: saving model to saved_models\\model_epoch_558_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0483 - val_loss: 0.0479\n",
      "Epoch 559/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0518\n",
      "Epoch 559: saving model to saved_models\\model_epoch_559_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0517 - val_loss: 0.0479\n",
      "Epoch 560/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0495\n",
      "Epoch 560: saving model to saved_models\\model_epoch_560_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0496 - val_loss: 0.0479\n",
      "Epoch 561/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0524\n",
      "Epoch 561: saving model to saved_models\\model_epoch_561_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0522 - val_loss: 0.0479\n",
      "Epoch 562/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0510\n",
      "Epoch 562: saving model to saved_models\\model_epoch_562_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0509 - val_loss: 0.0479\n",
      "Epoch 563/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0499\n",
      "Epoch 563: saving model to saved_models\\model_epoch_563_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0500 - val_loss: 0.0479\n",
      "Epoch 564/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0505\n",
      "Epoch 564: saving model to saved_models\\model_epoch_564_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0505 - val_loss: 0.0480\n",
      "Epoch 565/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0516\n",
      "Epoch 565: saving model to saved_models\\model_epoch_565_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0514 - val_loss: 0.0480\n",
      "Epoch 566/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0505\n",
      "Epoch 566: saving model to saved_models\\model_epoch_566_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0505 - val_loss: 0.0479\n",
      "Epoch 567/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0495\n",
      "Epoch 567: saving model to saved_models\\model_epoch_567_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0496 - val_loss: 0.0479\n",
      "Epoch 568/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0498\n",
      "Epoch 568: saving model to saved_models\\model_epoch_568_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0500 - val_loss: 0.0479\n",
      "Epoch 569/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0520\n",
      "Epoch 569: saving model to saved_models\\model_epoch_569_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0518 - val_loss: 0.0479\n",
      "Epoch 570/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0497\n",
      "Epoch 570: saving model to saved_models\\model_epoch_570_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0499 - val_loss: 0.0479\n",
      "Epoch 571/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0534\n",
      "Epoch 571: saving model to saved_models\\model_epoch_571_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0531 - val_loss: 0.0479\n",
      "Epoch 572/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0512\n",
      "Epoch 572: saving model to saved_models\\model_epoch_572_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0512 - val_loss: 0.0479\n",
      "Epoch 573/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0521\n",
      "Epoch 573: saving model to saved_models\\model_epoch_573_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0519 - val_loss: 0.0479\n",
      "Epoch 574/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0486\n",
      "Epoch 574: saving model to saved_models\\model_epoch_574_loss_0.0522.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0492 - val_loss: 0.0479\n",
      "Epoch 575/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0508\n",
      "Epoch 575: saving model to saved_models\\model_epoch_575_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0509 - val_loss: 0.0479\n",
      "Epoch 576/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0525\n",
      "Epoch 576: saving model to saved_models\\model_epoch_576_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0524 - val_loss: 0.0479\n",
      "Epoch 577/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0524\n",
      "Epoch 577: saving model to saved_models\\model_epoch_577_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0521 - val_loss: 0.0479\n",
      "Epoch 578/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0487\n",
      "Epoch 578: saving model to saved_models\\model_epoch_578_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0490 - val_loss: 0.0478\n",
      "Epoch 579/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0517\n",
      "Epoch 579: saving model to saved_models\\model_epoch_579_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0514 - val_loss: 0.0478\n",
      "Epoch 580/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0518\n",
      "Epoch 580: saving model to saved_models\\model_epoch_580_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0517 - val_loss: 0.0478\n",
      "Epoch 581/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0464\n",
      "Epoch 581: saving model to saved_models\\model_epoch_581_loss_0.0491.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0469 - val_loss: 0.0478\n",
      "Epoch 582/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0517\n",
      "Epoch 582: saving model to saved_models\\model_epoch_582_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0516 - val_loss: 0.0478\n",
      "Epoch 583/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0526\n",
      "Epoch 583: saving model to saved_models\\model_epoch_583_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0522 - val_loss: 0.0478\n",
      "Epoch 584/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0484\n",
      "Epoch 584: saving model to saved_models\\model_epoch_584_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0485 - val_loss: 0.0478\n",
      "Epoch 585/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0531\n",
      "Epoch 585: saving model to saved_models\\model_epoch_585_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0529 - val_loss: 0.0478\n",
      "Epoch 586/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0489\n",
      "Epoch 586: saving model to saved_models\\model_epoch_586_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0491 - val_loss: 0.0478\n",
      "Epoch 587/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0528\n",
      "Epoch 587: saving model to saved_models\\model_epoch_587_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0525 - val_loss: 0.0478\n",
      "Epoch 588/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0488\n",
      "Epoch 588: saving model to saved_models\\model_epoch_588_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0490 - val_loss: 0.0478\n",
      "Epoch 589/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0498\n",
      "Epoch 589: saving model to saved_models\\model_epoch_589_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0499 - val_loss: 0.0477\n",
      "Epoch 590/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0498\n",
      "Epoch 590: saving model to saved_models\\model_epoch_590_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0500 - val_loss: 0.0478\n",
      "Epoch 591/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0540\n",
      "Epoch 591: saving model to saved_models\\model_epoch_591_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0538 - val_loss: 0.0478\n",
      "Epoch 592/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0496\n",
      "Epoch 592: saving model to saved_models\\model_epoch_592_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0497 - val_loss: 0.0477\n",
      "Epoch 593/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0500\n",
      "Epoch 593: saving model to saved_models\\model_epoch_593_loss_0.0495.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0499 - val_loss: 0.0477\n",
      "Epoch 594/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0541\n",
      "Epoch 594: saving model to saved_models\\model_epoch_594_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0537 - val_loss: 0.0477\n",
      "Epoch 595/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0486\n",
      "Epoch 595: saving model to saved_models\\model_epoch_595_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0489 - val_loss: 0.0477\n",
      "Epoch 596/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0522\n",
      "Epoch 596: saving model to saved_models\\model_epoch_596_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0519 - val_loss: 0.0478\n",
      "Epoch 597/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0522\n",
      "Epoch 597: saving model to saved_models\\model_epoch_597_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0521 - val_loss: 0.0477\n",
      "Epoch 598/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0499\n",
      "Epoch 598: saving model to saved_models\\model_epoch_598_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0499 - val_loss: 0.0477\n",
      "Epoch 599/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0502\n",
      "Epoch 599: saving model to saved_models\\model_epoch_599_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0502 - val_loss: 0.0477\n",
      "Epoch 600/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0516\n",
      "Epoch 600: saving model to saved_models\\model_epoch_600_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0516 - val_loss: 0.0478\n",
      "Epoch 601/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0519\n",
      "Epoch 601: saving model to saved_models\\model_epoch_601_loss_0.0493.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0515 - val_loss: 0.0478\n",
      "Epoch 602/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0492\n",
      "Epoch 602: saving model to saved_models\\model_epoch_602_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0494 - val_loss: 0.0478\n",
      "Epoch 603/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0511\n",
      "Epoch 603: saving model to saved_models\\model_epoch_603_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0509 - val_loss: 0.0478\n",
      "Epoch 604/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0495\n",
      "Epoch 604: saving model to saved_models\\model_epoch_604_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0496 - val_loss: 0.0478\n",
      "Epoch 605/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0516\n",
      "Epoch 605: saving model to saved_models\\model_epoch_605_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0515 - val_loss: 0.0478\n",
      "Epoch 606/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0467\n",
      "Epoch 606: saving model to saved_models\\model_epoch_606_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0471 - val_loss: 0.0478\n",
      "Epoch 607/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0532\n",
      "Epoch 607: saving model to saved_models\\model_epoch_607_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0528 - val_loss: 0.0478\n",
      "Epoch 608/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0514\n",
      "Epoch 608: saving model to saved_models\\model_epoch_608_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0514 - val_loss: 0.0478\n",
      "Epoch 609/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0485\n",
      "Epoch 609: saving model to saved_models\\model_epoch_609_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0486 - val_loss: 0.0478\n",
      "Epoch 610/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0504\n",
      "Epoch 610: saving model to saved_models\\model_epoch_610_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0504 - val_loss: 0.0478\n",
      "Epoch 611/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0543\n",
      "Epoch 611: saving model to saved_models\\model_epoch_611_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0537 - val_loss: 0.0478\n",
      "Epoch 612/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0509\n",
      "Epoch 612: saving model to saved_models\\model_epoch_612_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0508 - val_loss: 0.0478\n",
      "Epoch 613/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0509\n",
      "Epoch 613: saving model to saved_models\\model_epoch_613_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0508 - val_loss: 0.0478\n",
      "Epoch 614/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0510\n",
      "Epoch 614: saving model to saved_models\\model_epoch_614_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0509 - val_loss: 0.0478\n",
      "Epoch 615/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0514\n",
      "Epoch 615: saving model to saved_models\\model_epoch_615_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0514 - val_loss: 0.0478\n",
      "Epoch 616/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0486\n",
      "Epoch 616: saving model to saved_models\\model_epoch_616_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0490 - val_loss: 0.0478\n",
      "Epoch 617/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0508\n",
      "Epoch 617: saving model to saved_models\\model_epoch_617_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0507 - val_loss: 0.0478\n",
      "Epoch 618/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0495\n",
      "Epoch 618: saving model to saved_models\\model_epoch_618_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0497 - val_loss: 0.0478\n",
      "Epoch 619/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0521\n",
      "Epoch 619: saving model to saved_models\\model_epoch_619_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0519 - val_loss: 0.0478\n",
      "Epoch 620/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0508\n",
      "Epoch 620: saving model to saved_models\\model_epoch_620_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0508 - val_loss: 0.0478\n",
      "Epoch 621/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0522\n",
      "Epoch 621: saving model to saved_models\\model_epoch_621_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0519 - val_loss: 0.0478\n",
      "Epoch 622/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0526\n",
      "Epoch 622: saving model to saved_models\\model_epoch_622_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0523 - val_loss: 0.0478\n",
      "Epoch 623/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0514\n",
      "Epoch 623: saving model to saved_models\\model_epoch_623_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0513 - val_loss: 0.0478\n",
      "Epoch 624/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0495\n",
      "Epoch 624: saving model to saved_models\\model_epoch_624_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0497 - val_loss: 0.0478\n",
      "Epoch 625/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0519\n",
      "Epoch 625: saving model to saved_models\\model_epoch_625_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0517 - val_loss: 0.0478\n",
      "Epoch 626/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0479\n",
      "Epoch 626: saving model to saved_models\\model_epoch_626_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0484 - val_loss: 0.0478\n",
      "Epoch 627/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0493\n",
      "Epoch 627: saving model to saved_models\\model_epoch_627_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0494 - val_loss: 0.0478\n",
      "Epoch 628/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0504\n",
      "Epoch 628: saving model to saved_models\\model_epoch_628_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0505 - val_loss: 0.0477\n",
      "Epoch 629/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0489\n",
      "Epoch 629: saving model to saved_models\\model_epoch_629_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0491 - val_loss: 0.0477\n",
      "Epoch 630/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0495\n",
      "Epoch 630: saving model to saved_models\\model_epoch_630_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0496 - val_loss: 0.0477\n",
      "Epoch 631/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0479\n",
      "Epoch 631: saving model to saved_models\\model_epoch_631_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0484 - val_loss: 0.0477\n",
      "Epoch 632/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0495\n",
      "Epoch 632: saving model to saved_models\\model_epoch_632_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0497 - val_loss: 0.0477\n",
      "Epoch 633/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0477\n",
      "Epoch 633: saving model to saved_models\\model_epoch_633_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0482 - val_loss: 0.0477\n",
      "Epoch 634/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0517\n",
      "Epoch 634: saving model to saved_models\\model_epoch_634_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0517 - val_loss: 0.0478\n",
      "Epoch 635/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0509\n",
      "Epoch 635: saving model to saved_models\\model_epoch_635_loss_0.0518.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0512 - val_loss: 0.0478\n",
      "Epoch 636/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0499\n",
      "Epoch 636: saving model to saved_models\\model_epoch_636_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0500 - val_loss: 0.0478\n",
      "Epoch 637/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0538\n",
      "Epoch 637: saving model to saved_models\\model_epoch_637_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0534 - val_loss: 0.0477\n",
      "Epoch 638/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0494\n",
      "Epoch 638: saving model to saved_models\\model_epoch_638_loss_0.0494.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0494 - val_loss: 0.0477\n",
      "Epoch 639/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0507\n",
      "Epoch 639: saving model to saved_models\\model_epoch_639_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0507 - val_loss: 0.0477\n",
      "Epoch 640/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0511\n",
      "Epoch 640: saving model to saved_models\\model_epoch_640_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0511 - val_loss: 0.0477\n",
      "Epoch 641/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0533\n",
      "Epoch 641: saving model to saved_models\\model_epoch_641_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0530 - val_loss: 0.0477\n",
      "Epoch 642/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0499\n",
      "Epoch 642: saving model to saved_models\\model_epoch_642_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0499 - val_loss: 0.0477\n",
      "Epoch 643/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0480\n",
      "Epoch 643: saving model to saved_models\\model_epoch_643_loss_0.0496.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0482 - val_loss: 0.0477\n",
      "Epoch 644/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0531\n",
      "Epoch 644: saving model to saved_models\\model_epoch_644_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0529 - val_loss: 0.0477\n",
      "Epoch 645/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0521\n",
      "Epoch 645: saving model to saved_models\\model_epoch_645_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0519 - val_loss: 0.0478\n",
      "Epoch 646/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0517\n",
      "Epoch 646: saving model to saved_models\\model_epoch_646_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0515 - val_loss: 0.0478\n",
      "Epoch 647/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0542\n",
      "Epoch 647: saving model to saved_models\\model_epoch_647_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0537 - val_loss: 0.0478\n",
      "Epoch 648/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0518\n",
      "Epoch 648: saving model to saved_models\\model_epoch_648_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0517 - val_loss: 0.0478\n",
      "Epoch 649/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0512\n",
      "Epoch 649: saving model to saved_models\\model_epoch_649_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0511 - val_loss: 0.0478\n",
      "Epoch 650/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0498\n",
      "Epoch 650: saving model to saved_models\\model_epoch_650_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0497 - val_loss: 0.0478\n",
      "Epoch 651/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0521\n",
      "Epoch 651: saving model to saved_models\\model_epoch_651_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0518 - val_loss: 0.0478\n",
      "Epoch 652/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0476\n",
      "Epoch 652: saving model to saved_models\\model_epoch_652_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0480 - val_loss: 0.0478\n",
      "Epoch 653/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0498\n",
      "Epoch 653: saving model to saved_models\\model_epoch_653_loss_0.0496.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0498 - val_loss: 0.0478\n",
      "Epoch 654/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0507\n",
      "Epoch 654: saving model to saved_models\\model_epoch_654_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0506 - val_loss: 0.0478\n",
      "Epoch 655/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0538\n",
      "Epoch 655: saving model to saved_models\\model_epoch_655_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0536 - val_loss: 0.0478\n",
      "Epoch 656/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0503\n",
      "Epoch 656: saving model to saved_models\\model_epoch_656_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0504 - val_loss: 0.0478\n",
      "Epoch 657/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0520\n",
      "Epoch 657: saving model to saved_models\\model_epoch_657_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0518 - val_loss: 0.0478\n",
      "Epoch 658/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0510\n",
      "Epoch 658: saving model to saved_models\\model_epoch_658_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0510 - val_loss: 0.0478\n",
      "Epoch 659/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0502\n",
      "Epoch 659: saving model to saved_models\\model_epoch_659_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0504 - val_loss: 0.0477\n",
      "Epoch 660/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0542\n",
      "Epoch 660: saving model to saved_models\\model_epoch_660_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0536 - val_loss: 0.0477\n",
      "Epoch 661/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0528\n",
      "Epoch 661: saving model to saved_models\\model_epoch_661_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0525 - val_loss: 0.0477\n",
      "Epoch 662/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0497\n",
      "Epoch 662: saving model to saved_models\\model_epoch_662_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0498 - val_loss: 0.0477\n",
      "Epoch 663/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0487\n",
      "Epoch 663: saving model to saved_models\\model_epoch_663_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0490 - val_loss: 0.0477\n",
      "Epoch 664/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0544\n",
      "Epoch 664: saving model to saved_models\\model_epoch_664_loss_0.0519.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0540 - val_loss: 0.0477\n",
      "Epoch 665/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0471\n",
      "Epoch 665: saving model to saved_models\\model_epoch_665_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0474 - val_loss: 0.0477\n",
      "Epoch 666/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0525\n",
      "Epoch 666: saving model to saved_models\\model_epoch_666_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0523 - val_loss: 0.0477\n",
      "Epoch 667/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0513\n",
      "Epoch 667: saving model to saved_models\\model_epoch_667_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0511 - val_loss: 0.0477\n",
      "Epoch 668/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0500\n",
      "Epoch 668: saving model to saved_models\\model_epoch_668_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0501 - val_loss: 0.0477\n",
      "Epoch 669/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0515\n",
      "Epoch 669: saving model to saved_models\\model_epoch_669_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0514 - val_loss: 0.0477\n",
      "Epoch 670/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0503\n",
      "Epoch 670: saving model to saved_models\\model_epoch_670_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0504 - val_loss: 0.0477\n",
      "Epoch 671/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0498\n",
      "Epoch 671: saving model to saved_models\\model_epoch_671_loss_0.0495.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0498 - val_loss: 0.0477\n",
      "Epoch 672/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0542\n",
      "Epoch 672: saving model to saved_models\\model_epoch_672_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0537 - val_loss: 0.0477\n",
      "Epoch 673/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0490\n",
      "Epoch 673: saving model to saved_models\\model_epoch_673_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0491 - val_loss: 0.0477\n",
      "Epoch 674/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0489\n",
      "Epoch 674: saving model to saved_models\\model_epoch_674_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0494 - val_loss: 0.0477\n",
      "Epoch 675/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0507\n",
      "Epoch 675: saving model to saved_models\\model_epoch_675_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0507 - val_loss: 0.0477\n",
      "Epoch 676/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0505\n",
      "Epoch 676: saving model to saved_models\\model_epoch_676_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0505 - val_loss: 0.0477\n",
      "Epoch 677/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0520\n",
      "Epoch 677: saving model to saved_models\\model_epoch_677_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0515 - val_loss: 0.0478\n",
      "Epoch 678/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0509\n",
      "Epoch 678: saving model to saved_models\\model_epoch_678_loss_0.0494.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0508 - val_loss: 0.0478\n",
      "Epoch 679/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0509\n",
      "Epoch 679: saving model to saved_models\\model_epoch_679_loss_0.0521.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0511 - val_loss: 0.0478\n",
      "Epoch 680/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0510\n",
      "Epoch 680: saving model to saved_models\\model_epoch_680_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0509 - val_loss: 0.0478\n",
      "Epoch 681/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0554\n",
      "Epoch 681: saving model to saved_models\\model_epoch_681_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0548 - val_loss: 0.0478\n",
      "Epoch 682/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0487\n",
      "Epoch 682: saving model to saved_models\\model_epoch_682_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0491 - val_loss: 0.0478\n",
      "Epoch 683/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0517\n",
      "Epoch 683: saving model to saved_models\\model_epoch_683_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0516 - val_loss: 0.0478\n",
      "Epoch 684/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0449\n",
      "Epoch 684: saving model to saved_models\\model_epoch_684_loss_0.0484.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0452 - val_loss: 0.0477\n",
      "Epoch 685/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0489\n",
      "Epoch 685: saving model to saved_models\\model_epoch_685_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0495 - val_loss: 0.0478\n",
      "Epoch 686/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0477\n",
      "Epoch 686: saving model to saved_models\\model_epoch_686_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0478 - val_loss: 0.0478\n",
      "Epoch 687/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0538\n",
      "Epoch 687: saving model to saved_models\\model_epoch_687_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0532 - val_loss: 0.0478\n",
      "Epoch 688/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0490\n",
      "Epoch 688: saving model to saved_models\\model_epoch_688_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0492 - val_loss: 0.0478\n",
      "Epoch 689/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0532\n",
      "Epoch 689: saving model to saved_models\\model_epoch_689_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0527 - val_loss: 0.0478\n",
      "Epoch 690/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0508\n",
      "Epoch 690: saving model to saved_models\\model_epoch_690_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0508 - val_loss: 0.0477\n",
      "Epoch 691/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0488\n",
      "Epoch 691: saving model to saved_models\\model_epoch_691_loss_0.0496.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0490 - val_loss: 0.0477\n",
      "Epoch 692/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0488\n",
      "Epoch 692: saving model to saved_models\\model_epoch_692_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0492 - val_loss: 0.0477\n",
      "Epoch 693/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0490\n",
      "Epoch 693: saving model to saved_models\\model_epoch_693_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0492 - val_loss: 0.0477\n",
      "Epoch 694/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0516\n",
      "Epoch 694: saving model to saved_models\\model_epoch_694_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0514 - val_loss: 0.0477\n",
      "Epoch 695/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0468\n",
      "Epoch 695: saving model to saved_models\\model_epoch_695_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0471 - val_loss: 0.0477\n",
      "Epoch 696/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0511\n",
      "Epoch 696: saving model to saved_models\\model_epoch_696_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0509 - val_loss: 0.0477\n",
      "Epoch 697/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0501\n",
      "Epoch 697: saving model to saved_models\\model_epoch_697_loss_0.0496.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0501 - val_loss: 0.0477\n",
      "Epoch 698/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0523\n",
      "Epoch 698: saving model to saved_models\\model_epoch_698_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0520 - val_loss: 0.0477\n",
      "Epoch 699/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0513\n",
      "Epoch 699: saving model to saved_models\\model_epoch_699_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0512 - val_loss: 0.0477\n",
      "Epoch 700/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0519\n",
      "Epoch 700: saving model to saved_models\\model_epoch_700_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0518 - val_loss: 0.0477\n",
      "Epoch 701/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0516\n",
      "Epoch 701: saving model to saved_models\\model_epoch_701_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0515 - val_loss: 0.0477\n",
      "Epoch 702/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0489\n",
      "Epoch 702: saving model to saved_models\\model_epoch_702_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0491 - val_loss: 0.0477\n",
      "Epoch 703/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0513\n",
      "Epoch 703: saving model to saved_models\\model_epoch_703_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0513 - val_loss: 0.0477\n",
      "Epoch 704/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0507\n",
      "Epoch 704: saving model to saved_models\\model_epoch_704_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0506 - val_loss: 0.0477\n",
      "Epoch 705/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0502\n",
      "Epoch 705: saving model to saved_models\\model_epoch_705_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0502 - val_loss: 0.0477\n",
      "Epoch 706/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0488\n",
      "Epoch 706: saving model to saved_models\\model_epoch_706_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0492 - val_loss: 0.0476\n",
      "Epoch 707/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0535\n",
      "Epoch 707: saving model to saved_models\\model_epoch_707_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0531 - val_loss: 0.0477\n",
      "Epoch 708/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0542\n",
      "Epoch 708: saving model to saved_models\\model_epoch_708_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0539 - val_loss: 0.0477\n",
      "Epoch 709/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0529\n",
      "Epoch 709: saving model to saved_models\\model_epoch_709_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0528 - val_loss: 0.0477\n",
      "Epoch 710/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0469\n",
      "Epoch 710: saving model to saved_models\\model_epoch_710_loss_0.0482.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0471 - val_loss: 0.0477\n",
      "Epoch 711/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0489\n",
      "Epoch 711: saving model to saved_models\\model_epoch_711_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0491 - val_loss: 0.0477\n",
      "Epoch 712/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0482\n",
      "Epoch 712: saving model to saved_models\\model_epoch_712_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0488 - val_loss: 0.0476\n",
      "Epoch 713/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0467\n",
      "Epoch 713: saving model to saved_models\\model_epoch_713_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0476 - val_loss: 0.0476\n",
      "Epoch 714/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0502\n",
      "Epoch 714: saving model to saved_models\\model_epoch_714_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0503 - val_loss: 0.0476\n",
      "Epoch 715/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0501\n",
      "Epoch 715: saving model to saved_models\\model_epoch_715_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0502 - val_loss: 0.0476\n",
      "Epoch 716/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0489\n",
      "Epoch 716: saving model to saved_models\\model_epoch_716_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0492 - val_loss: 0.0477\n",
      "Epoch 717/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0512\n",
      "Epoch 717: saving model to saved_models\\model_epoch_717_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0510 - val_loss: 0.0477\n",
      "Epoch 718/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0498\n",
      "Epoch 718: saving model to saved_models\\model_epoch_718_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0498 - val_loss: 0.0477\n",
      "Epoch 719/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0513\n",
      "Epoch 719: saving model to saved_models\\model_epoch_719_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0512 - val_loss: 0.0477\n",
      "Epoch 720/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0512\n",
      "Epoch 720: saving model to saved_models\\model_epoch_720_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0511 - val_loss: 0.0477\n",
      "Epoch 721/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0487\n",
      "Epoch 721: saving model to saved_models\\model_epoch_721_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0490 - val_loss: 0.0477\n",
      "Epoch 722/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0537\n",
      "Epoch 722: saving model to saved_models\\model_epoch_722_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0532 - val_loss: 0.0476\n",
      "Epoch 723/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0525\n",
      "Epoch 723: saving model to saved_models\\model_epoch_723_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0521 - val_loss: 0.0476\n",
      "Epoch 724/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0493\n",
      "Epoch 724: saving model to saved_models\\model_epoch_724_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0494 - val_loss: 0.0476\n",
      "Epoch 725/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0504\n",
      "Epoch 725: saving model to saved_models\\model_epoch_725_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0505 - val_loss: 0.0476\n",
      "Epoch 726/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0524\n",
      "Epoch 726: saving model to saved_models\\model_epoch_726_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0521 - val_loss: 0.0476\n",
      "Epoch 727/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0525\n",
      "Epoch 727: saving model to saved_models\\model_epoch_727_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0522 - val_loss: 0.0476\n",
      "Epoch 728/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0512\n",
      "Epoch 728: saving model to saved_models\\model_epoch_728_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0511 - val_loss: 0.0476\n",
      "Epoch 729/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0526\n",
      "Epoch 729: saving model to saved_models\\model_epoch_729_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0522 - val_loss: 0.0476\n",
      "Epoch 730/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0496\n",
      "Epoch 730: saving model to saved_models\\model_epoch_730_loss_0.0494.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0496 - val_loss: 0.0476\n",
      "Epoch 731/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0502\n",
      "Epoch 731: saving model to saved_models\\model_epoch_731_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0503 - val_loss: 0.0476\n",
      "Epoch 732/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0529\n",
      "Epoch 732: saving model to saved_models\\model_epoch_732_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0525 - val_loss: 0.0476\n",
      "Epoch 733/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0508\n",
      "Epoch 733: saving model to saved_models\\model_epoch_733_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0506 - val_loss: 0.0476\n",
      "Epoch 734/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0535\n",
      "Epoch 734: saving model to saved_models\\model_epoch_734_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0530 - val_loss: 0.0476\n",
      "Epoch 735/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0481\n",
      "Epoch 735: saving model to saved_models\\model_epoch_735_loss_0.0493.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0483 - val_loss: 0.0476\n",
      "Epoch 736/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0488\n",
      "Epoch 736: saving model to saved_models\\model_epoch_736_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0490 - val_loss: 0.0476\n",
      "Epoch 737/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0485\n",
      "Epoch 737: saving model to saved_models\\model_epoch_737_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0487 - val_loss: 0.0476\n",
      "Epoch 738/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0501\n",
      "Epoch 738: saving model to saved_models\\model_epoch_738_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0501 - val_loss: 0.0476\n",
      "Epoch 739/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0493\n",
      "Epoch 739: saving model to saved_models\\model_epoch_739_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0494 - val_loss: 0.0476\n",
      "Epoch 740/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0520\n",
      "Epoch 740: saving model to saved_models\\model_epoch_740_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0519 - val_loss: 0.0476\n",
      "Epoch 741/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0502\n",
      "Epoch 741: saving model to saved_models\\model_epoch_741_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0502 - val_loss: 0.0476\n",
      "Epoch 742/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0512\n",
      "Epoch 742: saving model to saved_models\\model_epoch_742_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0510 - val_loss: 0.0476\n",
      "Epoch 743/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0515\n",
      "Epoch 743: saving model to saved_models\\model_epoch_743_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0511 - val_loss: 0.0476\n",
      "Epoch 744/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0554\n",
      "Epoch 744: saving model to saved_models\\model_epoch_744_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0546 - val_loss: 0.0476\n",
      "Epoch 745/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0476\n",
      "Epoch 745: saving model to saved_models\\model_epoch_745_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0480 - val_loss: 0.0475\n",
      "Epoch 746/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0504\n",
      "Epoch 746: saving model to saved_models\\model_epoch_746_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0506 - val_loss: 0.0476\n",
      "Epoch 747/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0530\n",
      "Epoch 747: saving model to saved_models\\model_epoch_747_loss_0.0524.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0529 - val_loss: 0.0475\n",
      "Epoch 748/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0481\n",
      "Epoch 748: saving model to saved_models\\model_epoch_748_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0484 - val_loss: 0.0475\n",
      "Epoch 749/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0565\n",
      "Epoch 749: saving model to saved_models\\model_epoch_749_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0557 - val_loss: 0.0475\n",
      "Epoch 750/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0513\n",
      "Epoch 750: saving model to saved_models\\model_epoch_750_loss_0.0496.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0510 - val_loss: 0.0475\n",
      "Epoch 751/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0538\n",
      "Epoch 751: saving model to saved_models\\model_epoch_751_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0534 - val_loss: 0.0475\n",
      "Epoch 752/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0498\n",
      "Epoch 752: saving model to saved_models\\model_epoch_752_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0500 - val_loss: 0.0475\n",
      "Epoch 753/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0515\n",
      "Epoch 753: saving model to saved_models\\model_epoch_753_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0514 - val_loss: 0.0475\n",
      "Epoch 754/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0492\n",
      "Epoch 754: saving model to saved_models\\model_epoch_754_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0493 - val_loss: 0.0475\n",
      "Epoch 755/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0512\n",
      "Epoch 755: saving model to saved_models\\model_epoch_755_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0513 - val_loss: 0.0475\n",
      "Epoch 756/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0533\n",
      "Epoch 756: saving model to saved_models\\model_epoch_756_loss_0.0496.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0527 - val_loss: 0.0475\n",
      "Epoch 757/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0517\n",
      "Epoch 757: saving model to saved_models\\model_epoch_757_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0513 - val_loss: 0.0475\n",
      "Epoch 758/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0472\n",
      "Epoch 758: saving model to saved_models\\model_epoch_758_loss_0.0493.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0475 - val_loss: 0.0475\n",
      "Epoch 759/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0479\n",
      "Epoch 759: saving model to saved_models\\model_epoch_759_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0482 - val_loss: 0.0475\n",
      "Epoch 760/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0476\n",
      "Epoch 760: saving model to saved_models\\model_epoch_760_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0480 - val_loss: 0.0475\n",
      "Epoch 761/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0538\n",
      "Epoch 761: saving model to saved_models\\model_epoch_761_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0534 - val_loss: 0.0475\n",
      "Epoch 762/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0514\n",
      "Epoch 762: saving model to saved_models\\model_epoch_762_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0513 - val_loss: 0.0475\n",
      "Epoch 763/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0492\n",
      "Epoch 763: saving model to saved_models\\model_epoch_763_loss_0.0491.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0492 - val_loss: 0.0474\n",
      "Epoch 764/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0519\n",
      "Epoch 764: saving model to saved_models\\model_epoch_764_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0516 - val_loss: 0.0475\n",
      "Epoch 765/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0516\n",
      "Epoch 765: saving model to saved_models\\model_epoch_765_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0515 - val_loss: 0.0475\n",
      "Epoch 766/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0479\n",
      "Epoch 766: saving model to saved_models\\model_epoch_766_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0483 - val_loss: 0.0475\n",
      "Epoch 767/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0468\n",
      "Epoch 767: saving model to saved_models\\model_epoch_767_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0474 - val_loss: 0.0475\n",
      "Epoch 768/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0500\n",
      "Epoch 768: saving model to saved_models\\model_epoch_768_loss_0.0489.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0499 - val_loss: 0.0475\n",
      "Epoch 769/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0501\n",
      "Epoch 769: saving model to saved_models\\model_epoch_769_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0501 - val_loss: 0.0475\n",
      "Epoch 770/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0537\n",
      "Epoch 770: saving model to saved_models\\model_epoch_770_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0535 - val_loss: 0.0475\n",
      "Epoch 771/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0479\n",
      "Epoch 771: saving model to saved_models\\model_epoch_771_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0483 - val_loss: 0.0475\n",
      "Epoch 772/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0508\n",
      "Epoch 772: saving model to saved_models\\model_epoch_772_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0507 - val_loss: 0.0475\n",
      "Epoch 773/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0519\n",
      "Epoch 773: saving model to saved_models\\model_epoch_773_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0517 - val_loss: 0.0475\n",
      "Epoch 774/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0503\n",
      "Epoch 774: saving model to saved_models\\model_epoch_774_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0504 - val_loss: 0.0475\n",
      "Epoch 775/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0479\n",
      "Epoch 775: saving model to saved_models\\model_epoch_775_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0482 - val_loss: 0.0475\n",
      "Epoch 776/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0490\n",
      "Epoch 776: saving model to saved_models\\model_epoch_776_loss_0.0494.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0491 - val_loss: 0.0475\n",
      "Epoch 777/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0489\n",
      "Epoch 777: saving model to saved_models\\model_epoch_777_loss_0.0516.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0493 - val_loss: 0.0475\n",
      "Epoch 778/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0519\n",
      "Epoch 778: saving model to saved_models\\model_epoch_778_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0518 - val_loss: 0.0475\n",
      "Epoch 779/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0481\n",
      "Epoch 779: saving model to saved_models\\model_epoch_779_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0482 - val_loss: 0.0475\n",
      "Epoch 780/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0493\n",
      "Epoch 780: saving model to saved_models\\model_epoch_780_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0494 - val_loss: 0.0474\n",
      "Epoch 781/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0539\n",
      "Epoch 781: saving model to saved_models\\model_epoch_781_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0534 - val_loss: 0.0475\n",
      "Epoch 782/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0508\n",
      "Epoch 782: saving model to saved_models\\model_epoch_782_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0509 - val_loss: 0.0475\n",
      "Epoch 783/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0521\n",
      "Epoch 783: saving model to saved_models\\model_epoch_783_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0519 - val_loss: 0.0475\n",
      "Epoch 784/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0515\n",
      "Epoch 784: saving model to saved_models\\model_epoch_784_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0512 - val_loss: 0.0475\n",
      "Epoch 785/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0465\n",
      "Epoch 785: saving model to saved_models\\model_epoch_785_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0470 - val_loss: 0.0475\n",
      "Epoch 786/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0509\n",
      "Epoch 786: saving model to saved_models\\model_epoch_786_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0508 - val_loss: 0.0475\n",
      "Epoch 787/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0489\n",
      "Epoch 787: saving model to saved_models\\model_epoch_787_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0491 - val_loss: 0.0474\n",
      "Epoch 788/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0513\n",
      "Epoch 788: saving model to saved_models\\model_epoch_788_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0512 - val_loss: 0.0474\n",
      "Epoch 789/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0504\n",
      "Epoch 789: saving model to saved_models\\model_epoch_789_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0505 - val_loss: 0.0474\n",
      "Epoch 790/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0522\n",
      "Epoch 790: saving model to saved_models\\model_epoch_790_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0520 - val_loss: 0.0474\n",
      "Epoch 791/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0487\n",
      "Epoch 791: saving model to saved_models\\model_epoch_791_loss_0.0496.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0488 - val_loss: 0.0474\n",
      "Epoch 792/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0501\n",
      "Epoch 792: saving model to saved_models\\model_epoch_792_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0501 - val_loss: 0.0474\n",
      "Epoch 793/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0518\n",
      "Epoch 793: saving model to saved_models\\model_epoch_793_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0516 - val_loss: 0.0474\n",
      "Epoch 794/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0483\n",
      "Epoch 794: saving model to saved_models\\model_epoch_794_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0486 - val_loss: 0.0474\n",
      "Epoch 795/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0488\n",
      "Epoch 795: saving model to saved_models\\model_epoch_795_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0491 - val_loss: 0.0474\n",
      "Epoch 796/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0454\n",
      "Epoch 796: saving model to saved_models\\model_epoch_796_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0461 - val_loss: 0.0474\n",
      "Epoch 797/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0483\n",
      "Epoch 797: saving model to saved_models\\model_epoch_797_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0485 - val_loss: 0.0474\n",
      "Epoch 798/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0491\n",
      "Epoch 798: saving model to saved_models\\model_epoch_798_loss_0.0493.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0492 - val_loss: 0.0474\n",
      "Epoch 799/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0486\n",
      "Epoch 799: saving model to saved_models\\model_epoch_799_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0489 - val_loss: 0.0474\n",
      "Epoch 800/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0481\n",
      "Epoch 800: saving model to saved_models\\model_epoch_800_loss_0.0494.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0483 - val_loss: 0.0474\n",
      "Epoch 801/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0498\n",
      "Epoch 801: saving model to saved_models\\model_epoch_801_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0498 - val_loss: 0.0474\n",
      "Epoch 802/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0510\n",
      "Epoch 802: saving model to saved_models\\model_epoch_802_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0509 - val_loss: 0.0475\n",
      "Epoch 803/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0490\n",
      "Epoch 803: saving model to saved_models\\model_epoch_803_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0493 - val_loss: 0.0474\n",
      "Epoch 804/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0498\n",
      "Epoch 804: saving model to saved_models\\model_epoch_804_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0499 - val_loss: 0.0474\n",
      "Epoch 805/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0460\n",
      "Epoch 805: saving model to saved_models\\model_epoch_805_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0467 - val_loss: 0.0474\n",
      "Epoch 806/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0516\n",
      "Epoch 806: saving model to saved_models\\model_epoch_806_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0514 - val_loss: 0.0474\n",
      "Epoch 807/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0493\n",
      "Epoch 807: saving model to saved_models\\model_epoch_807_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0495 - val_loss: 0.0474\n",
      "Epoch 808/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0526\n",
      "Epoch 808: saving model to saved_models\\model_epoch_808_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0522 - val_loss: 0.0474\n",
      "Epoch 809/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0492\n",
      "Epoch 809: saving model to saved_models\\model_epoch_809_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0493 - val_loss: 0.0473\n",
      "Epoch 810/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0483\n",
      "Epoch 810: saving model to saved_models\\model_epoch_810_loss_0.0486.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0484 - val_loss: 0.0473\n",
      "Epoch 811/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0513\n",
      "Epoch 811: saving model to saved_models\\model_epoch_811_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0512 - val_loss: 0.0473\n",
      "Epoch 812/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0513\n",
      "Epoch 812: saving model to saved_models\\model_epoch_812_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0510 - val_loss: 0.0473\n",
      "Epoch 813/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0530\n",
      "Epoch 813: saving model to saved_models\\model_epoch_813_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0528 - val_loss: 0.0473\n",
      "Epoch 814/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0523\n",
      "Epoch 814: saving model to saved_models\\model_epoch_814_loss_0.0511.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0522 - val_loss: 0.0473\n",
      "Epoch 815/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0512\n",
      "Epoch 815: saving model to saved_models\\model_epoch_815_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0511 - val_loss: 0.0473\n",
      "Epoch 816/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0487\n",
      "Epoch 816: saving model to saved_models\\model_epoch_816_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0490 - val_loss: 0.0473\n",
      "Epoch 817/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0487\n",
      "Epoch 817: saving model to saved_models\\model_epoch_817_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0490 - val_loss: 0.0473\n",
      "Epoch 818/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0457\n",
      "Epoch 818: saving model to saved_models\\model_epoch_818_loss_0.0493.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0463 - val_loss: 0.0473\n",
      "Epoch 819/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0545\n",
      "Epoch 819: saving model to saved_models\\model_epoch_819_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0534 - val_loss: 0.0473\n",
      "Epoch 820/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0483\n",
      "Epoch 820: saving model to saved_models\\model_epoch_820_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0486 - val_loss: 0.0473\n",
      "Epoch 821/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0482\n",
      "Epoch 821: saving model to saved_models\\model_epoch_821_loss_0.0492.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0484 - val_loss: 0.0474\n",
      "Epoch 822/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0467\n",
      "Epoch 822: saving model to saved_models\\model_epoch_822_loss_0.0487.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0470 - val_loss: 0.0474\n",
      "Epoch 823/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0512\n",
      "Epoch 823: saving model to saved_models\\model_epoch_823_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0510 - val_loss: 0.0474\n",
      "Epoch 824/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0537\n",
      "Epoch 824: saving model to saved_models\\model_epoch_824_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0534 - val_loss: 0.0474\n",
      "Epoch 825/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0493\n",
      "Epoch 825: saving model to saved_models\\model_epoch_825_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0495 - val_loss: 0.0474\n",
      "Epoch 826/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0489\n",
      "Epoch 826: saving model to saved_models\\model_epoch_826_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0489 - val_loss: 0.0474\n",
      "Epoch 827/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0513\n",
      "Epoch 827: saving model to saved_models\\model_epoch_827_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0511 - val_loss: 0.0474\n",
      "Epoch 828/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0511\n",
      "Epoch 828: saving model to saved_models\\model_epoch_828_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0509 - val_loss: 0.0474\n",
      "Epoch 829/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0529\n",
      "Epoch 829: saving model to saved_models\\model_epoch_829_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0525 - val_loss: 0.0474\n",
      "Epoch 830/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0488\n",
      "Epoch 830: saving model to saved_models\\model_epoch_830_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0490 - val_loss: 0.0474\n",
      "Epoch 831/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0513\n",
      "Epoch 831: saving model to saved_models\\model_epoch_831_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0513 - val_loss: 0.0473\n",
      "Epoch 832/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0516\n",
      "Epoch 832: saving model to saved_models\\model_epoch_832_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0516 - val_loss: 0.0473\n",
      "Epoch 833/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0503\n",
      "Epoch 833: saving model to saved_models\\model_epoch_833_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0504 - val_loss: 0.0473\n",
      "Epoch 834/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0519\n",
      "Epoch 834: saving model to saved_models\\model_epoch_834_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0517 - val_loss: 0.0473\n",
      "Epoch 835/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0530\n",
      "Epoch 835: saving model to saved_models\\model_epoch_835_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0528 - val_loss: 0.0473\n",
      "Epoch 836/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0485\n",
      "Epoch 836: saving model to saved_models\\model_epoch_836_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0488 - val_loss: 0.0473\n",
      "Epoch 837/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0505\n",
      "Epoch 837: saving model to saved_models\\model_epoch_837_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0505 - val_loss: 0.0473\n",
      "Epoch 838/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0494\n",
      "Epoch 838: saving model to saved_models\\model_epoch_838_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0495 - val_loss: 0.0473\n",
      "Epoch 839/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0483\n",
      "Epoch 839: saving model to saved_models\\model_epoch_839_loss_0.0490.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0484 - val_loss: 0.0473\n",
      "Epoch 840/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0501\n",
      "Epoch 840: saving model to saved_models\\model_epoch_840_loss_0.0493.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0500 - val_loss: 0.0473\n",
      "Epoch 841/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0510\n",
      "Epoch 841: saving model to saved_models\\model_epoch_841_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0509 - val_loss: 0.0473\n",
      "Epoch 842/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0515\n",
      "Epoch 842: saving model to saved_models\\model_epoch_842_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0515 - val_loss: 0.0473\n",
      "Epoch 843/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0472\n",
      "Epoch 843: saving model to saved_models\\model_epoch_843_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0477 - val_loss: 0.0473\n",
      "Epoch 844/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0487\n",
      "Epoch 844: saving model to saved_models\\model_epoch_844_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0490 - val_loss: 0.0473\n",
      "Epoch 845/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0512\n",
      "Epoch 845: saving model to saved_models\\model_epoch_845_loss_0.0494.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0510 - val_loss: 0.0473\n",
      "Epoch 846/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0517\n",
      "Epoch 846: saving model to saved_models\\model_epoch_846_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0515 - val_loss: 0.0473\n",
      "Epoch 847/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0494\n",
      "Epoch 847: saving model to saved_models\\model_epoch_847_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0495 - val_loss: 0.0472\n",
      "Epoch 848/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0491\n",
      "Epoch 848: saving model to saved_models\\model_epoch_848_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0492 - val_loss: 0.0473\n",
      "Epoch 849/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0485\n",
      "Epoch 849: saving model to saved_models\\model_epoch_849_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0487 - val_loss: 0.0472\n",
      "Epoch 850/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0499\n",
      "Epoch 850: saving model to saved_models\\model_epoch_850_loss_0.0490.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0498 - val_loss: 0.0473\n",
      "Epoch 851/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0526\n",
      "Epoch 851: saving model to saved_models\\model_epoch_851_loss_0.0515.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0524 - val_loss: 0.0473\n",
      "Epoch 852/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0497\n",
      "Epoch 852: saving model to saved_models\\model_epoch_852_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0498 - val_loss: 0.0472\n",
      "Epoch 853/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0476\n",
      "Epoch 853: saving model to saved_models\\model_epoch_853_loss_0.0478.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0476 - val_loss: 0.0473\n",
      "Epoch 854/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0501\n",
      "Epoch 854: saving model to saved_models\\model_epoch_854_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0501 - val_loss: 0.0473\n",
      "Epoch 855/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0507\n",
      "Epoch 855: saving model to saved_models\\model_epoch_855_loss_0.0495.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0505 - val_loss: 0.0473\n",
      "Epoch 856/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0547\n",
      "Epoch 856: saving model to saved_models\\model_epoch_856_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0544 - val_loss: 0.0473\n",
      "Epoch 857/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0501\n",
      "Epoch 857: saving model to saved_models\\model_epoch_857_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0500 - val_loss: 0.0473\n",
      "Epoch 858/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0505\n",
      "Epoch 858: saving model to saved_models\\model_epoch_858_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0505 - val_loss: 0.0473\n",
      "Epoch 859/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0466\n",
      "Epoch 859: saving model to saved_models\\model_epoch_859_loss_0.0491.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0470 - val_loss: 0.0473\n",
      "Epoch 860/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0508\n",
      "Epoch 860: saving model to saved_models\\model_epoch_860_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0508 - val_loss: 0.0473\n",
      "Epoch 861/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0485\n",
      "Epoch 861: saving model to saved_models\\model_epoch_861_loss_0.0496.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0486 - val_loss: 0.0473\n",
      "Epoch 862/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0528\n",
      "Epoch 862: saving model to saved_models\\model_epoch_862_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0526 - val_loss: 0.0472\n",
      "Epoch 863/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0488\n",
      "Epoch 863: saving model to saved_models\\model_epoch_863_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0490 - val_loss: 0.0473\n",
      "Epoch 864/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0465\n",
      "Epoch 864: saving model to saved_models\\model_epoch_864_loss_0.0496.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0470 - val_loss: 0.0473\n",
      "Epoch 865/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0505\n",
      "Epoch 865: saving model to saved_models\\model_epoch_865_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0505 - val_loss: 0.0473\n",
      "Epoch 866/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0491\n",
      "Epoch 866: saving model to saved_models\\model_epoch_866_loss_0.0488.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0490 - val_loss: 0.0473\n",
      "Epoch 867/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0502\n",
      "Epoch 867: saving model to saved_models\\model_epoch_867_loss_0.0492.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0501 - val_loss: 0.0473\n",
      "Epoch 868/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0513\n",
      "Epoch 868: saving model to saved_models\\model_epoch_868_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0511 - val_loss: 0.0472\n",
      "Epoch 869/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0487\n",
      "Epoch 869: saving model to saved_models\\model_epoch_869_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0490 - val_loss: 0.0472\n",
      "Epoch 870/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0499\n",
      "Epoch 870: saving model to saved_models\\model_epoch_870_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0499 - val_loss: 0.0472\n",
      "Epoch 871/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0485\n",
      "Epoch 871: saving model to saved_models\\model_epoch_871_loss_0.0488.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0485 - val_loss: 0.0472\n",
      "Epoch 872/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0494\n",
      "Epoch 872: saving model to saved_models\\model_epoch_872_loss_0.0503.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0495 - val_loss: 0.0472\n",
      "Epoch 873/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0522\n",
      "Epoch 873: saving model to saved_models\\model_epoch_873_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0522 - val_loss: 0.0472\n",
      "Epoch 874/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0511\n",
      "Epoch 874: saving model to saved_models\\model_epoch_874_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0511 - val_loss: 0.0472\n",
      "Epoch 875/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0498\n",
      "Epoch 875: saving model to saved_models\\model_epoch_875_loss_0.0494.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0497 - val_loss: 0.0473\n",
      "Epoch 876/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0501\n",
      "Epoch 876: saving model to saved_models\\model_epoch_876_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0502 - val_loss: 0.0472\n",
      "Epoch 877/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0489\n",
      "Epoch 877: saving model to saved_models\\model_epoch_877_loss_0.0491.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0489 - val_loss: 0.0472\n",
      "Epoch 878/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0477\n",
      "Epoch 878: saving model to saved_models\\model_epoch_878_loss_0.0496.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0478 - val_loss: 0.0472\n",
      "Epoch 879/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0506\n",
      "Epoch 879: saving model to saved_models\\model_epoch_879_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0506 - val_loss: 0.0472\n",
      "Epoch 880/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0512\n",
      "Epoch 880: saving model to saved_models\\model_epoch_880_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0511 - val_loss: 0.0472\n",
      "Epoch 881/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0525\n",
      "Epoch 881: saving model to saved_models\\model_epoch_881_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0523 - val_loss: 0.0472\n",
      "Epoch 882/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0476\n",
      "Epoch 882: saving model to saved_models\\model_epoch_882_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0479 - val_loss: 0.0472\n",
      "Epoch 883/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0514\n",
      "Epoch 883: saving model to saved_models\\model_epoch_883_loss_0.0494.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0509 - val_loss: 0.0472\n",
      "Epoch 884/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0484\n",
      "Epoch 884: saving model to saved_models\\model_epoch_884_loss_0.0492.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0487 - val_loss: 0.0472\n",
      "Epoch 885/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0502\n",
      "Epoch 885: saving model to saved_models\\model_epoch_885_loss_0.0488.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0500 - val_loss: 0.0472\n",
      "Epoch 886/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0511\n",
      "Epoch 886: saving model to saved_models\\model_epoch_886_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0511 - val_loss: 0.0472\n",
      "Epoch 887/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0517\n",
      "Epoch 887: saving model to saved_models\\model_epoch_887_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0515 - val_loss: 0.0472\n",
      "Epoch 888/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0517\n",
      "Epoch 888: saving model to saved_models\\model_epoch_888_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0514 - val_loss: 0.0472\n",
      "Epoch 889/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0482\n",
      "Epoch 889: saving model to saved_models\\model_epoch_889_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0487 - val_loss: 0.0472\n",
      "Epoch 890/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0502\n",
      "Epoch 890: saving model to saved_models\\model_epoch_890_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0502 - val_loss: 0.0472\n",
      "Epoch 891/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0500\n",
      "Epoch 891: saving model to saved_models\\model_epoch_891_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0501 - val_loss: 0.0472\n",
      "Epoch 892/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0534\n",
      "Epoch 892: saving model to saved_models\\model_epoch_892_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0530 - val_loss: 0.0472\n",
      "Epoch 893/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0491\n",
      "Epoch 893: saving model to saved_models\\model_epoch_893_loss_0.0488.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0490 - val_loss: 0.0472\n",
      "Epoch 894/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0503\n",
      "Epoch 894: saving model to saved_models\\model_epoch_894_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0504 - val_loss: 0.0472\n",
      "Epoch 895/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0493\n",
      "Epoch 895: saving model to saved_models\\model_epoch_895_loss_0.0495.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0494 - val_loss: 0.0472\n",
      "Epoch 896/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0478\n",
      "Epoch 896: saving model to saved_models\\model_epoch_896_loss_0.0494.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0481 - val_loss: 0.0472\n",
      "Epoch 897/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0455\n",
      "Epoch 897: saving model to saved_models\\model_epoch_897_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0462 - val_loss: 0.0472\n",
      "Epoch 898/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0519\n",
      "Epoch 898: saving model to saved_models\\model_epoch_898_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0516 - val_loss: 0.0472\n",
      "Epoch 899/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0510\n",
      "Epoch 899: saving model to saved_models\\model_epoch_899_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0510 - val_loss: 0.0472\n",
      "Epoch 900/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0501\n",
      "Epoch 900: saving model to saved_models\\model_epoch_900_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0500 - val_loss: 0.0472\n",
      "Epoch 901/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0511\n",
      "Epoch 901: saving model to saved_models\\model_epoch_901_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0509 - val_loss: 0.0473\n",
      "Epoch 902/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0497\n",
      "Epoch 902: saving model to saved_models\\model_epoch_902_loss_0.0494.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0496 - val_loss: 0.0472\n",
      "Epoch 903/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0511\n",
      "Epoch 903: saving model to saved_models\\model_epoch_903_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0509 - val_loss: 0.0473\n",
      "Epoch 904/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0479\n",
      "Epoch 904: saving model to saved_models\\model_epoch_904_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0482 - val_loss: 0.0472\n",
      "Epoch 905/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0493\n",
      "Epoch 905: saving model to saved_models\\model_epoch_905_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0494 - val_loss: 0.0473\n",
      "Epoch 906/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0518\n",
      "Epoch 906: saving model to saved_models\\model_epoch_906_loss_0.0508.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0516 - val_loss: 0.0472\n",
      "Epoch 907/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0506\n",
      "Epoch 907: saving model to saved_models\\model_epoch_907_loss_0.0489.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0505 - val_loss: 0.0472\n",
      "Epoch 908/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0524\n",
      "Epoch 908: saving model to saved_models\\model_epoch_908_loss_0.0512.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0522 - val_loss: 0.0472\n",
      "Epoch 909/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0478\n",
      "Epoch 909: saving model to saved_models\\model_epoch_909_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0482 - val_loss: 0.0472\n",
      "Epoch 910/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0516\n",
      "Epoch 910: saving model to saved_models\\model_epoch_910_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0515 - val_loss: 0.0472\n",
      "Epoch 911/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0514\n",
      "Epoch 911: saving model to saved_models\\model_epoch_911_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0512 - val_loss: 0.0472\n",
      "Epoch 912/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0511\n",
      "Epoch 912: saving model to saved_models\\model_epoch_912_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0510 - val_loss: 0.0472\n",
      "Epoch 913/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0508\n",
      "Epoch 913: saving model to saved_models\\model_epoch_913_loss_0.0489.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0505 - val_loss: 0.0472\n",
      "Epoch 914/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0526\n",
      "Epoch 914: saving model to saved_models\\model_epoch_914_loss_0.0492.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0521 - val_loss: 0.0472\n",
      "Epoch 915/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0514\n",
      "Epoch 915: saving model to saved_models\\model_epoch_915_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0513 - val_loss: 0.0472\n",
      "Epoch 916/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0487\n",
      "Epoch 916: saving model to saved_models\\model_epoch_916_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0490 - val_loss: 0.0472\n",
      "Epoch 917/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0522\n",
      "Epoch 917: saving model to saved_models\\model_epoch_917_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0520 - val_loss: 0.0472\n",
      "Epoch 918/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0469\n",
      "Epoch 918: saving model to saved_models\\model_epoch_918_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0477 - val_loss: 0.0472\n",
      "Epoch 919/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0496\n",
      "Epoch 919: saving model to saved_models\\model_epoch_919_loss_0.0506.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0498 - val_loss: 0.0472\n",
      "Epoch 920/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0467\n",
      "Epoch 920: saving model to saved_models\\model_epoch_920_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0470 - val_loss: 0.0472\n",
      "Epoch 921/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0507\n",
      "Epoch 921: saving model to saved_models\\model_epoch_921_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0506 - val_loss: 0.0472\n",
      "Epoch 922/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0513\n",
      "Epoch 922: saving model to saved_models\\model_epoch_922_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0511 - val_loss: 0.0471\n",
      "Epoch 923/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0478\n",
      "Epoch 923: saving model to saved_models\\model_epoch_923_loss_0.0487.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0479 - val_loss: 0.0472\n",
      "Epoch 924/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0484\n",
      "Epoch 924: saving model to saved_models\\model_epoch_924_loss_0.0494.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0485 - val_loss: 0.0472\n",
      "Epoch 925/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0492\n",
      "Epoch 925: saving model to saved_models\\model_epoch_925_loss_0.0509.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0493 - val_loss: 0.0472\n",
      "Epoch 926/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0479\n",
      "Epoch 926: saving model to saved_models\\model_epoch_926_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0481 - val_loss: 0.0472\n",
      "Epoch 927/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0504\n",
      "Epoch 927: saving model to saved_models\\model_epoch_927_loss_0.0513.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0506 - val_loss: 0.0471\n",
      "Epoch 928/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0485\n",
      "Epoch 928: saving model to saved_models\\model_epoch_928_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0488 - val_loss: 0.0472\n",
      "Epoch 929/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0514\n",
      "Epoch 929: saving model to saved_models\\model_epoch_929_loss_0.0514.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0514 - val_loss: 0.0472\n",
      "Epoch 930/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0474\n",
      "Epoch 930: saving model to saved_models\\model_epoch_930_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0477 - val_loss: 0.0472\n",
      "Epoch 931/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0468\n",
      "Epoch 931: saving model to saved_models\\model_epoch_931_loss_0.0496.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0470 - val_loss: 0.0472\n",
      "Epoch 932/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0475\n",
      "Epoch 932: saving model to saved_models\\model_epoch_932_loss_0.0495.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0478 - val_loss: 0.0472\n",
      "Epoch 933/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0511\n",
      "Epoch 933: saving model to saved_models\\model_epoch_933_loss_0.0488.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0506 - val_loss: 0.0472\n",
      "Epoch 934/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0497\n",
      "Epoch 934: saving model to saved_models\\model_epoch_934_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0497 - val_loss: 0.0472\n",
      "Epoch 935/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0492\n",
      "Epoch 935: saving model to saved_models\\model_epoch_935_loss_0.0489.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0491 - val_loss: 0.0471\n",
      "Epoch 936/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0504\n",
      "Epoch 936: saving model to saved_models\\model_epoch_936_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0504 - val_loss: 0.0472\n",
      "Epoch 937/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0513\n",
      "Epoch 937: saving model to saved_models\\model_epoch_937_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0512 - val_loss: 0.0472\n",
      "Epoch 938/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0479\n",
      "Epoch 938: saving model to saved_models\\model_epoch_938_loss_0.0488.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0481 - val_loss: 0.0471\n",
      "Epoch 939/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0489\n",
      "Epoch 939: saving model to saved_models\\model_epoch_939_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0490 - val_loss: 0.0471\n",
      "Epoch 940/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0491\n",
      "Epoch 940: saving model to saved_models\\model_epoch_940_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0493 - val_loss: 0.0471\n",
      "Epoch 941/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0499\n",
      "Epoch 941: saving model to saved_models\\model_epoch_941_loss_0.0493.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0498 - val_loss: 0.0471\n",
      "Epoch 942/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0488\n",
      "Epoch 942: saving model to saved_models\\model_epoch_942_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0489 - val_loss: 0.0471\n",
      "Epoch 943/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0511\n",
      "Epoch 943: saving model to saved_models\\model_epoch_943_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0509 - val_loss: 0.0471\n",
      "Epoch 944/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0485\n",
      "Epoch 944: saving model to saved_models\\model_epoch_944_loss_0.0484.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0485 - val_loss: 0.0471\n",
      "Epoch 945/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0497\n",
      "Epoch 945: saving model to saved_models\\model_epoch_945_loss_0.0492.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0496 - val_loss: 0.0471\n",
      "Epoch 946/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0484\n",
      "Epoch 946: saving model to saved_models\\model_epoch_946_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0485 - val_loss: 0.0471\n",
      "Epoch 947/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0479\n",
      "Epoch 947: saving model to saved_models\\model_epoch_947_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0482 - val_loss: 0.0471\n",
      "Epoch 948/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0485\n",
      "Epoch 948: saving model to saved_models\\model_epoch_948_loss_0.0482.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0485 - val_loss: 0.0471\n",
      "Epoch 949/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0487\n",
      "Epoch 949: saving model to saved_models\\model_epoch_949_loss_0.0495.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0488 - val_loss: 0.0471\n",
      "Epoch 950/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0527\n",
      "Epoch 950: saving model to saved_models\\model_epoch_950_loss_0.0492.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0524 - val_loss: 0.0471\n",
      "Epoch 951/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0495\n",
      "Epoch 951: saving model to saved_models\\model_epoch_951_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0495 - val_loss: 0.0471\n",
      "Epoch 952/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0498\n",
      "Epoch 952: saving model to saved_models\\model_epoch_952_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0498 - val_loss: 0.0472\n",
      "Epoch 953/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0501\n",
      "Epoch 953: saving model to saved_models\\model_epoch_953_loss_0.0493.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0499 - val_loss: 0.0471\n",
      "Epoch 954/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0513\n",
      "Epoch 954: saving model to saved_models\\model_epoch_954_loss_0.0491.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0510 - val_loss: 0.0471\n",
      "Epoch 955/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0517\n",
      "Epoch 955: saving model to saved_models\\model_epoch_955_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0516 - val_loss: 0.0471\n",
      "Epoch 956/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0515\n",
      "Epoch 956: saving model to saved_models\\model_epoch_956_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0514 - val_loss: 0.0472\n",
      "Epoch 957/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0498\n",
      "Epoch 957: saving model to saved_models\\model_epoch_957_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0498 - val_loss: 0.0472\n",
      "Epoch 958/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0508\n",
      "Epoch 958: saving model to saved_models\\model_epoch_958_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0508 - val_loss: 0.0472\n",
      "Epoch 959/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0539\n",
      "Epoch 959: saving model to saved_models\\model_epoch_959_loss_0.0507.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0534 - val_loss: 0.0471\n",
      "Epoch 960/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0495\n",
      "Epoch 960: saving model to saved_models\\model_epoch_960_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0496 - val_loss: 0.0472\n",
      "Epoch 961/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0477\n",
      "Epoch 961: saving model to saved_models\\model_epoch_961_loss_0.0480.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0477 - val_loss: 0.0472\n",
      "Epoch 962/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0478\n",
      "Epoch 962: saving model to saved_models\\model_epoch_962_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0481 - val_loss: 0.0471\n",
      "Epoch 963/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0509\n",
      "Epoch 963: saving model to saved_models\\model_epoch_963_loss_0.0510.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0509 - val_loss: 0.0471\n",
      "Epoch 964/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0500\n",
      "Epoch 964: saving model to saved_models\\model_epoch_964_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0500 - val_loss: 0.0471\n",
      "Epoch 965/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0467\n",
      "Epoch 965: saving model to saved_models\\model_epoch_965_loss_0.0488.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0470 - val_loss: 0.0471\n",
      "Epoch 966/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0514\n",
      "Epoch 966: saving model to saved_models\\model_epoch_966_loss_0.0505.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0513 - val_loss: 0.0471\n",
      "Epoch 967/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0481\n",
      "Epoch 967: saving model to saved_models\\model_epoch_967_loss_0.0484.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0482 - val_loss: 0.0471\n",
      "Epoch 968/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0469\n",
      "Epoch 968: saving model to saved_models\\model_epoch_968_loss_0.0490.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0472 - val_loss: 0.0471\n",
      "Epoch 969/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0476\n",
      "Epoch 969: saving model to saved_models\\model_epoch_969_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0478 - val_loss: 0.0471\n",
      "Epoch 970/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0460\n",
      "Epoch 970: saving model to saved_models\\model_epoch_970_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0466 - val_loss: 0.0471\n",
      "Epoch 971/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0506\n",
      "Epoch 971: saving model to saved_models\\model_epoch_971_loss_0.0493.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0504 - val_loss: 0.0471\n",
      "Epoch 972/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0485\n",
      "Epoch 972: saving model to saved_models\\model_epoch_972_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0487 - val_loss: 0.0471\n",
      "Epoch 973/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0515\n",
      "Epoch 973: saving model to saved_models\\model_epoch_973_loss_0.0517.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0515 - val_loss: 0.0471\n",
      "Epoch 974/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0491\n",
      "Epoch 974: saving model to saved_models\\model_epoch_974_loss_0.0494.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0491 - val_loss: 0.0470\n",
      "Epoch 975/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0525\n",
      "Epoch 975: saving model to saved_models\\model_epoch_975_loss_0.0490.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0517 - val_loss: 0.0470\n",
      "Epoch 976/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0497\n",
      "Epoch 976: saving model to saved_models\\model_epoch_976_loss_0.0491.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0496 - val_loss: 0.0470\n",
      "Epoch 977/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0486\n",
      "Epoch 977: saving model to saved_models\\model_epoch_977_loss_0.0495.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0487 - val_loss: 0.0471\n",
      "Epoch 978/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0487\n",
      "Epoch 978: saving model to saved_models\\model_epoch_978_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0490 - val_loss: 0.0471\n",
      "Epoch 979/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0503\n",
      "Epoch 979: saving model to saved_models\\model_epoch_979_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0502 - val_loss: 0.0471\n",
      "Epoch 980/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0479\n",
      "Epoch 980: saving model to saved_models\\model_epoch_980_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0481 - val_loss: 0.0471\n",
      "Epoch 981/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0487\n",
      "Epoch 981: saving model to saved_models\\model_epoch_981_loss_0.0494.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0488 - val_loss: 0.0471\n",
      "Epoch 982/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0519\n",
      "Epoch 982: saving model to saved_models\\model_epoch_982_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0517 - val_loss: 0.0471\n",
      "Epoch 983/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0497\n",
      "Epoch 983: saving model to saved_models\\model_epoch_983_loss_0.0492.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0496 - val_loss: 0.0470\n",
      "Epoch 984/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0502\n",
      "Epoch 984: saving model to saved_models\\model_epoch_984_loss_0.0504.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0502 - val_loss: 0.0470\n",
      "Epoch 985/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0501\n",
      "Epoch 985: saving model to saved_models\\model_epoch_985_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0500 - val_loss: 0.0470\n",
      "Epoch 986/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0495\n",
      "Epoch 986: saving model to saved_models\\model_epoch_986_loss_0.0489.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0494 - val_loss: 0.0470\n",
      "Epoch 987/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0482\n",
      "Epoch 987: saving model to saved_models\\model_epoch_987_loss_0.0484.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0482 - val_loss: 0.0470\n",
      "Epoch 988/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0501\n",
      "Epoch 988: saving model to saved_models\\model_epoch_988_loss_0.0496.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0500 - val_loss: 0.0470\n",
      "Epoch 989/1000\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0472\n",
      "Epoch 989: saving model to saved_models\\model_epoch_989_loss_0.0492.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0476 - val_loss: 0.0470\n",
      "Epoch 990/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0479\n",
      "Epoch 990: saving model to saved_models\\model_epoch_990_loss_0.0497.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0482 - val_loss: 0.0470\n",
      "Epoch 991/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0493\n",
      "Epoch 991: saving model to saved_models\\model_epoch_991_loss_0.0487.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0492 - val_loss: 0.0470\n",
      "Epoch 992/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0500\n",
      "Epoch 992: saving model to saved_models\\model_epoch_992_loss_0.0492.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0499 - val_loss: 0.0470\n",
      "Epoch 993/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0505\n",
      "Epoch 993: saving model to saved_models\\model_epoch_993_loss_0.0488.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0504 - val_loss: 0.0470\n",
      "Epoch 994/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0496\n",
      "Epoch 994: saving model to saved_models\\model_epoch_994_loss_0.0501.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0497 - val_loss: 0.0470\n",
      "Epoch 995/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0490\n",
      "Epoch 995: saving model to saved_models\\model_epoch_995_loss_0.0491.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0490 - val_loss: 0.0470\n",
      "Epoch 996/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0497\n",
      "Epoch 996: saving model to saved_models\\model_epoch_996_loss_0.0498.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0497 - val_loss: 0.0471\n",
      "Epoch 997/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0502\n",
      "Epoch 997: saving model to saved_models\\model_epoch_997_loss_0.0499.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0501 - val_loss: 0.0470\n",
      "Epoch 998/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0525\n",
      "Epoch 998: saving model to saved_models\\model_epoch_998_loss_0.0502.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0521 - val_loss: 0.0471\n",
      "Epoch 999/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0528\n",
      "Epoch 999: saving model to saved_models\\model_epoch_999_loss_0.0500.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0523 - val_loss: 0.0470\n",
      "Epoch 1000/1000\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0508\n",
      "Epoch 1000: saving model to saved_models\\model_epoch_1000_loss_0.0494.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0506 - val_loss: 0.0471\n"
     ]
    }
   ],
   "source": [
    "model = load_least_loss_model(save_dir)\n",
    "if model is None:\n",
    "# Build a new model if no checkpoint is found\n",
    "    model = build_model(optimizer='Adadelta')\n",
    "# Train the model for a set number of epochs (e.g., 10)\n",
    "history = model.fit(\n",
    "    trainX, trainY, \n",
    "    batch_size=52, \n",
    "    epochs=1000, \n",
    "    verbose=1, \n",
    "    validation_data=(validX, validY),\n",
    "    callbacks=[checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model with the least loss: model_epoch_853_loss_0.0478.keras\n"
     ]
    }
   ],
   "source": [
    "model_latest = load_least_loss_model(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001AFF92E4A40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 363ms/stepWARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001AFF92E4A40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 208ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_latest = model_latest.predict(validX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.496237  ],\n",
       "       [0.5163231 ],\n",
       "       [0.5184133 ],\n",
       "       [0.49595007],\n",
       "       [0.46923393],\n",
       "       [0.44353396],\n",
       "       [0.4375357 ],\n",
       "       [0.4689798 ],\n",
       "       [0.49060935],\n",
       "       [0.4948485 ],\n",
       "       [0.47377682],\n",
       "       [0.44959867],\n",
       "       [0.42557317],\n",
       "       [0.42134318],\n",
       "       [0.45486584],\n",
       "       [0.47746468],\n",
       "       [0.48318225],\n",
       "       [0.46381786],\n",
       "       [0.4397384 ],\n",
       "       [0.41660246],\n",
       "       [0.4129954 ],\n",
       "       [0.44648615],\n",
       "       [0.47018358],\n",
       "       [0.47639447],\n",
       "       [0.45683765],\n",
       "       [0.4316412 ],\n",
       "       [0.40743417],\n",
       "       [0.399688  ],\n",
       "       [0.42850414],\n",
       "       [0.44767678],\n",
       "       [0.4479612 ],\n",
       "       [0.42369637],\n",
       "       [0.39645174],\n",
       "       [0.3680673 ],\n",
       "       [0.35949668],\n",
       "       [0.38986495],\n",
       "       [0.40839204],\n",
       "       [0.41031432],\n",
       "       [0.38764042],\n",
       "       [0.359834  ],\n",
       "       [0.3342689 ],\n",
       "       [0.32915965],\n",
       "       [0.36257   ],\n",
       "       [0.38551888],\n",
       "       [0.3925166 ],\n",
       "       [0.37507004],\n",
       "       [0.3518167 ],\n",
       "       [0.3295101 ],\n",
       "       [0.32806367],\n",
       "       [0.36166063],\n",
       "       [0.386168  ],\n",
       "       [0.3930083 ],\n",
       "       [0.37474537],\n",
       "       [0.35282958],\n",
       "       [0.33382204],\n",
       "       [0.33294353],\n",
       "       [0.36900893],\n",
       "       [0.39330348],\n",
       "       [0.40002707],\n",
       "       [0.38149604],\n",
       "       [0.35768872],\n",
       "       [0.33217168],\n",
       "       [0.32470676],\n",
       "       [0.35487002],\n",
       "       [0.37169683],\n",
       "       [0.37195006],\n",
       "       [0.34908086],\n",
       "       [0.32021034],\n",
       "       [0.29387867],\n",
       "       [0.28980863]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136.1332630092393\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stock_prediction(y_pred=y_pred_latest, validY=validY, scaler=scaler, numerical_cols=numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    }
   ],
   "source": [
    "temp_pre = model_latest.predict(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.04720222660616\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stock_prediction(y_pred=temp_pre, validY=trainY, scaler=scaler, numerical_cols=numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (time_series_env)",
   "language": "python",
   "name": "time_series_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
